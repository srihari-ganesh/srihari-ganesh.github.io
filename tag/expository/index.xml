<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>expository | Srihari Ganesh</title><link>https://srihari-ganesh.github.io/tag/expository/</link><atom:link href="https://srihari-ganesh.github.io/tag/expository/index.xml" rel="self" type="application/rss+xml"/><description>expository</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 26 Sep 2023 00:00:00 +0000</lastBuildDate><image><url>https://srihari-ganesh.github.io/media/icon_hu238e72ff877ecedb95a45ec9a2f2431b_15216_512x512_fill_lanczos_center_3.png</url><title>expository</title><link>https://srihari-ganesh.github.io/tag/expository/</link></image><item><title>Week 3: Conditional Probability Examples and Random Variables</title><link>https://srihari-ganesh.github.io/stat110/week3/</link><pubDate>Tue, 26 Sep 2023 00:00:00 +0000</pubDate><guid>https://srihari-ganesh.github.io/stat110/week3/</guid><description>&lt;h2 id="0-logistical-info">0. Logistical Info&lt;/h2>
&lt;ul>
&lt;li>Section date: 9/27&lt;/li>
&lt;li>Associated lectures: 9/19, 9/21&lt;/li>
&lt;li>Associated pset: Pset 2, due 9/29&lt;/li>
&lt;li>Office hours on 9/27 from 7-9pm at Quincy Dining Hall&lt;/li>
&lt;li>Remember to fill out the attendance form&lt;/li>
&lt;li>Scroll to &lt;a href="#4-summary">section 4&lt;/a> for a concise content summary.&lt;/li>
&lt;/ul>
&lt;h3 id="01-summary--practice-problem-pdfs">0.1 Summary + Practice Problem PDFs&lt;/h3>
&lt;p>&lt;a href="https://srihari-ganesh.github.io/uploads/stat110/Section%203%20Handout.pdf" target="_blank">Summary + Practice Problems PDF&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://srihari-ganesh.github.io/uploads/stat110/Section%203%20Solutions.pdf" target="_blank">Practice Problem Solutions PDF&lt;/a>&lt;/p>
&lt;h2 id="1-examples-from-class">1. Examples from class&lt;/h2>
&lt;p>The lecture on 9/19 was full of examples of conditional probability. Here are my takeaways for each. I did not rewrite the examples because solutions are quite well-written in the book and/or in lecture.&lt;/p>
&lt;h3 id="11-winter-girl-examples-225-227-in-the-book">1.1 Winter girl (Examples 2.2.5-2.2.7 in the book)&lt;/h3>
&lt;ul>
&lt;li>Define your events as specifically as possible, there are a lot of details that surprisingly can change probabilities.&lt;/li>
&lt;li>See if you can simplify your events (both mathematically and logically). For example, if $A$ is the event that there&amp;rsquo;s at least one girl and $B$ is the event that there are two girls, $P(A, B) = P(B)$ since if there are two girls, there is automatically at least one girls.&lt;/li>
&lt;/ul>
&lt;h3 id="12-monty-hall-example-271-and-many-practice-problems-in-the-book">1.2 Monty Hall (Example 2.7.1 and many practice problems in the book)&lt;/h3>
&lt;p>You can use the Law of Total Probability in some extreme ways! Condition on things that make your life much, much easier - in Monty Hall problems (and the variants that Joe likes to write), I very often condition on the location of the car or use Bayes&amp;rsquo; rule to move information about the car&amp;rsquo;s location into the condition!&lt;/p>
&lt;h3 id="13-simpsons-paradox-example-283-in-the-book">1.3 Simpson&amp;rsquo;s paradox (Example 2.8.3 in the book)&lt;/h3>
&lt;p>I think it&amp;rsquo;s a good to develop the skill of coming up with similar paradoxes - at the very least, it can test your understanding of probability. My understanding of this phenomenon is that there are two tasks - a hard and an easy task. Doctor A might have a better success rate in each task, but Doctor B can still have a higher overall success rate.&lt;/p>
&lt;p>This happens because Doctor A does more of the harder task, which drags their average down, while Doctor B inflates their average by doing the easier task more often. There are some other intuitive corollaries - like how some students may learn a lot but have lower GPAs then other students because they take a higher proportion of challenging classes.&lt;/p>
&lt;p>To construct these paradoxes, I think you need a hard task (where both doctors have a &amp;ldquo;low&amp;rdquo; success rate) and an easy task (where both doctors have a higher success rate). Then doctor A has to do more of the hard task, while doctor B needs to do more of the easy task, to weight their averages differently.&lt;/p>
&lt;h3 id="14-gamblers-ruin-example-273-in-the-book">1.4 Gambler&amp;rsquo;s ruin (Example 2.7.3 in the book)&lt;/h3>
&lt;p>You will be assessed (in pset and/or exam) on your ability to apply the gambler&amp;rsquo;s ruin result in other contexts, but you will never have to re-derive it. So you can figure out how variables in your problem correspond to gambler&amp;rsquo;s ruin (or even set up the difference equation) then just jump to plugging in the solution given.&lt;/p>
&lt;p>In the gambler&amp;rsquo;s ruin problem, gambler $A$ starts with $i$ dollars and gambler $B$ starts with $N-i$ dollars. They keep making 1 dollar bets (which gambler $A$ has a probability $p$ of winning) until someone runs out of money (either gambler $A$ has $0$ dollars or gambler $B$ has 0 dollars). We often define $q = 1-p$ for notational convenience.&lt;/p>
&lt;p>If we define $p_i$ to be the probability that gambler $A$ wins if they start with $i$ dollars, then using first-step analysis we find that
$$
p_i = p_{i+1} p + p_{i-1}q.
$$
This gives a difference equation solution of
$$
p_i = \begin{cases} \frac{1 - (\frac{q}{p})^i}{1 - (\frac{q}{p})^N}&amp;amp; p \ne 1/2\\
\frac{i}{N}&amp;amp; p = 1/2 \end{cases}
$$&lt;/p>
&lt;p>To match a problem to this, you should&lt;/p>
&lt;ul>
&lt;li>Make sure that &amp;ldquo;bets&amp;rdquo; are worth 1 dollar each.&lt;/li>
&lt;li>Make sure that gambler $A$ loses if they hit 0 dollars, and wins if they hit some fixed amount of dollars ($N$)&lt;/li>
&lt;li>Make sure there is a constant probability of winning each bet.&lt;/li>
&lt;/ul>
&lt;h2 id="2-random-variables">2. Random variables&lt;/h2>
&lt;h3 id="21-definition">2.1 Definition&lt;/h3>
&lt;p>A &lt;strong>random variable&lt;/strong> summarizes some experiment. So if you have a sample space $S$, for each possible outcome $\omega \in S$, your random variable takes on a certain (real number). Here are some examples of random variables:&lt;/p>
&lt;ul>
&lt;li>Say we&amp;rsquo;re rolling a die, so $S$ is the set of possible rolls. Then we could have $X = 1$ if we roll a $1$, $X = 2$ if we roll a $2$, and so on.&lt;/li>
&lt;li>We could define another random variable $Y$ to be the square of the roll. so $Y = 1$ if we roll a 1, $Y = 16$ if we roll a $4$, etc.&lt;/li>
&lt;li>Random variables don&amp;rsquo;t have to take on different values for every outcome. So we could have $Z = 2$ if we roll an even number and $Z = 1$ if we roll an odd number.&lt;/li>
&lt;li>They also don&amp;rsquo;t have to be discrete values - we could have a random variable $T$ represent the exact temperature in the room right now.&lt;/li>
&lt;/ul>
&lt;h3 id="22-defining-discrete-random-variables">2.2 Defining discrete random variables&lt;/h3>
&lt;p>A random variable is &lt;strong>discrete&lt;/strong> if it has a finite or countably infinite number of values (something like $1, 2, 3, 4, \ldots$ is countably infinite. If instead your random variable can take on any value in an interval - like any real number, or any real number between 2 and 4, etc. - then it is uncountable).&lt;/p>
&lt;p>We can uniquely describe a random variable by its &lt;strong>probability mass function&lt;/strong>. This basically tells us the probability that the random variable takes on each possible value. For example, the probability mass function for the first dice-roll example, $X$ is
$$
P(X = x) = \begin{cases}
\frac{1}{6} &amp;amp; x \in \{1, 2, 3, 4, 5, 6\}\\
0 &amp;amp; \text{else}.
\end{cases}
$$
The little $x$ is a dummy variable - it&amp;rsquo;s just a general way of going through every possible value. For example, we can now tell that there is a $1/6$ probability that $X = 4$, which corresponds to a $1/6$ probability that we roll a $4$, which makes sense.&lt;/p>
&lt;p>Some important facts:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;$X = 1$&amp;rdquo; is an event, so we can take its probability. We &lt;em>cannot&lt;/em> take the probability of a random variable, so $P(X)$ is a category error.&lt;/li>
&lt;li>When writing a PMF
&lt;ul>
&lt;li>Every probability should be between $0$ and $1$ (inclusive), which holds for all probabilities.&lt;/li>
&lt;li>The probabilities in the PMF should sum to $1$:
$$
\sum_{x \in \mathbb{R}} P(X = x) = 1.
$$
This comes from both axioms of probability, since the events for each possible value of $X$ partition the entire sample space.&lt;/li>
&lt;li>I always have the &amp;ldquo;$0$, else&amp;rdquo; statement.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>The &lt;strong>support&lt;/strong> of a random variable is the set of possible values it can take on. So the support for $X$ is ${1, 2, 3, 4, 5, 6}$, and the support for $Z$ is ${1, 2}$, and so on. You should always define the support, too.&lt;/li>
&lt;/ul>
&lt;h3 id="23-a-more-mathy-definition-of-random-variables">2.3 A more mathy definition of random variables&lt;/h3>
&lt;p>Random variables are functions. If notation makes more sense to you, maybe this will be useful.&lt;/p>
&lt;p>Remember that in any random experiment, we have a sample space $S$, where each element of $S$ is a possible outcome. Exactly one of those outcomes will happen. You can think of a random variable $X$ as a function that maps outcomes to the real number line, so $X : S \to \mathbb{R}$. So if some outcome $\omega \in S$ happens, then the random variable gives us the real number $X(\omega)$. There&amp;rsquo;s nothing random about the function $X$ - each outcome always goes to the same real number - but instead the randomness comes from which outcome actually ends up happening.&lt;/p>
&lt;p>So when we think about PMFs and any probabilities with random variables, we&amp;rsquo;re using a bit of shorthand. It&amp;rsquo;s not immediately obvious that $X = x$ is an event, so let&amp;rsquo;s translate (again, remember $x$ is just a fixed number. I could just as easily use $y$ or $a$ as a variable, or $0$ or $1.5$ or $-17$ if I want a specific value):
\begin{align}
P(X = x) = P(\{\omega \in S : X(\omega) = x\})
\end{align}
That set, $\{\omega \in S : X(\omega) = x\}$, is a subset of the sample space and thus is definitely an event. We can take a probability of that. Note that there can be multiple outcomes in this subset, which is the same as saying that $X$ is &lt;em>not injective&lt;/em>.&lt;/p>
&lt;p>So when we start talking about fancier random varibles - like $X^2$ - we can still dissect the probabilities
\begin{align}
P(X^2 = y) &amp;amp;= P(\{\omega \in S : X^2(\omega) = y\})\\
&amp;amp;= P(\{\omega \in S : X(\omega) = \sqrt{y} \text{ or } X(\omega) = -\sqrt{y}\})\\
&amp;amp;= P((X = \sqrt{y}) \cup (X = -\sqrt{y}))\\
&amp;amp;= P(X = \sqrt{y}) + P(X = -\sqrt{y}),
\end{align}
assuming $y$ is positive and splitting up the probability in the last step because the two events are disjoint (a random variable can&amp;rsquo;t equal two different values at the same time).&lt;/p>
&lt;p>The support can also now be redefined as the function - basically, the support is $\{x \in \mathbb{R} : \text{ there exists } \omega \in S \text{ such that } X(\omega) = x\}$.&lt;/p>
&lt;h2 id="3-distributions">3. Distributions&lt;/h2>
&lt;p>A distribution is a type of random variable. I think this makes the most sense through example. For discrete distributions (which correspond to discrete random variables), we usually motivate them with a story and maybe some counting. &lt;strong>Stories are extremely important and should be internalized,&lt;/strong> not just the PMFs.&lt;/p>
&lt;h3 id="31-bernoulli-distribution">3.1 Bernoulli Distribution&lt;/h3>
&lt;p>You perform an experiment that consists of $1$ trial, where the possible outcomes are success or failure. There is a probability $p$ of success and probability $q = 1-p$ of failure. This is summarized by a random variable $X$, where $X = 1$ if the trial is a success and $X = 0$ if it is a failure. We then say $X$ is distributed Bernoulli with parameter $p$, or in notation, $X \sim \mathrm{Bern}(p)$.&lt;/p>
&lt;p>The PMF is
$$
P(X = x) = \begin{cases}
p &amp;amp; x = 1\\
q &amp;amp; x = 0\\
0 &amp;amp; \text{else}
\end{cases}
$$&lt;/p>
&lt;p>For a concrete example, a rigged coin toss has a probability $p = 0.7$ of landing heads (success) and probability $q = 0.3$ of landing tails (failure). If $X = 1$ when the coin lands heads and $X = 0$ when it lands tails, then $X \sim \mathrm{Bern}(0.7)$.&lt;/p>
&lt;p>Note that you CANNOT set a random variable &lt;em>equal&lt;/em> to a distribution. You have to use the $\sim$ symbol and say &amp;ldquo;distributed as.&amp;rdquo;&lt;/p>
&lt;h3 id="32-binomial-distribution">3.2 Binomial Distribution&lt;/h3>
&lt;p>You perform an experiment with $n$, independent Bernoulli trials, each of which is a success with the same probability $p$. Then the random variable $Y$, the number of successful trials, is distributed Binomial with $n$ trials and success probability $p$. In notation, $Y \sim \mathrm{Bin}(n, p)$.&lt;/p>
&lt;p>We can find the PMF with some counting:
\begin{align}
P(Y = y) &amp;amp;= \begin{cases}
\binom{n}{y} p^y (1-p)^{n-y} &amp;amp; y \in \{0, 1, 2, \ldots, n\}\\
0 &amp;amp; \text{else}.
\end{cases}
\end{align}&lt;/p>
&lt;p>NOTE: a Binomial random variable $Y$ can be represented as the sum of $n$ independent Bernoulli random variables, each with success probability $p$.&lt;/p>
&lt;h2 id="4-summary">4. Summary&lt;/h2>
&lt;h3 id="41-examples-from-class">4.1 Examples from class&lt;/h3>
&lt;p>Some takeaways:&lt;/p>
&lt;ul>
&lt;li>Define events very specifically (winter girl)&lt;/li>
&lt;li>See if you can simplify your problems with logic, not just relying on grinding through math (winter girl)&lt;/li>
&lt;li>Use the Law of Total Probability to condition on anything/everything you wish you knew
&lt;ul>
&lt;li>In Monty Hall, you can often condition on the location of the car!&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>To mimic Simpson&amp;rsquo;s paradox, set up some &amp;ldquo;hard&amp;rdquo; and &amp;ldquo;easy&amp;rdquo; tasks and make the better doctor do more of the hard tasks&lt;/li>
&lt;li>Learn how to turn a problem into the gambler&amp;rsquo;s ruin problem:
&lt;ul>
&lt;li>Make losing happen at $0$, and winning happen at some fixed $N$&lt;/li>
&lt;li>Make sure each bet/step is only one dollar in either direction&lt;/li>
&lt;li>Make sure the probability of winning each individual bet is constant&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="42-random-variables">4.2 Random variables&lt;/h3>
&lt;p>&lt;strong>Random variables&lt;/strong> are a numerical (real number) summary of the outcome of your experiment. So for each possible outcome, the random variable takes on a certain value. Multiple outcomes can lead to the same value of the random variable. The &lt;strong>support&lt;/strong> of a random variable is the set of possible values it can take on.&lt;/p>
&lt;p>We define discrete random variables by their &lt;strong>probability mass function&lt;/strong>. You should define the probability $P(X = x)$ for each $x$ in the random variable&amp;rsquo;s support, and always write probability $0$ for any value of $x$ that is not in the support. The PMF should always give valid probabilities, and should sum to $1$.&lt;/p>
&lt;h3 id="43-distributions">4.3 Distributions&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Bernoulli distribution&lt;/strong>: you conduct a single trial that succeeds with probability $p$. $X = 1$ if the trial succeeds and $X = 0$ if it fails. Then $X \sim \mathrm{Bern}(p)$ and has a PMF
$$
P(X = x) = \begin{cases}
p &amp;amp; x = 1\\
1 - p &amp;amp; x = 0\\
0 &amp;amp; \text{else}
\end{cases}
$$&lt;/li>
&lt;li>&lt;strong>Binomial distribution&lt;/strong>: you conducts $n$ independent trials that each succeed with probability $p$. $Y$ is the total number of successes among the $n$ trials. Then $Y \sim \mathrm{Bin}(n, p)$ and the PMF is
$$
P(Y = y) = \begin{cases}
\binom{n}{y} p^y (1-p)^{n-y} &amp;amp; y \in \{0, 1, \ldots, n\}\\
0 &amp;amp; \text{else}
\end{cases}
$$&lt;/li>
&lt;/ul></description></item><item><title>Week 2: Conditional Probability</title><link>https://srihari-ganesh.github.io/stat110/week2/</link><pubDate>Sat, 16 Sep 2023 00:00:00 +0000</pubDate><guid>https://srihari-ganesh.github.io/stat110/week2/</guid><description>&lt;h2 id="0-logistical-info">0. Logistical Info&lt;/h2>
&lt;ul>
&lt;li>Section date: 9/20&lt;/li>
&lt;li>Associated lectures: 9/12, 9/14&lt;/li>
&lt;li>Associated pset: Pset 2, due 9/22&lt;/li>
&lt;li>Office hours on 9/20 from 7-9pm at Quincy Dining Hall&lt;/li>
&lt;li>Remember to fill out the attendance form&lt;/li>
&lt;li>Scroll to &lt;a href="#5-summary">section 5&lt;/a> for a concise content summary.&lt;/li>
&lt;/ul>
&lt;h3 id="01-summary--practice-problem-pdfs">0.1 Summary + Practice Problem PDFs&lt;/h3>
&lt;p>&lt;a href="https://srihari-ganesh.github.io/uploads/stat110/Section%202%20Handout.pdf" target="_blank">Summary + Practice Problems PDF&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://srihari-ganesh.github.io/uploads/stat110/Section%202%20Solutions.pdf" target="_blank">Practice Problem Solutions PDF&lt;/a>&lt;/p>
&lt;h2 id="1-brushing-up-on-the-definition-of-probability">1. Brushing up on the definition of probability&lt;/h2>
&lt;p>We&amp;rsquo;ll restate the axioms for the general definition of probability:&lt;/p>
&lt;div class="alert alert-note">
&lt;div>
&lt;p>&lt;strong>Definition of probability&lt;/strong>:&lt;br>
There are just two axioms (rules that probabilities have to follow):&lt;/p>
&lt;ol>
&lt;li>$P(S) = 1, P(\emptyset) = 0.$&lt;/li>
&lt;li>If events $A_1, A_2, \ldots$ are disjoint, then $$
P\left( \bigcup_{j=1}^\infty A_j\right) = \sum_{j=1}^\infty P(A_j).
$$&lt;/li>
&lt;/ol>
&lt;p>In other words, if $A_1, A_2, \ldots$ partition some event $B$, then $P(B) = \sum_{j=1}^\infty P(A_j)$.&lt;/p>
&lt;/div>
&lt;/div>
&lt;!-- axioms are what mathematicians use to encode intuitive definitions -->
&lt;div class="alert alert-warning">
&lt;div>
&lt;p>&lt;strong>Tips for calculating probabilities&lt;/strong>:&lt;/p>
&lt;ol>
&lt;li>Define events for every aspect of the problem (e.g., &amp;ldquo;$A$ = the event that it rains tomorrow, $B$ = the event that it rained today&amp;rdquo;)&lt;/li>
&lt;li>Write out the probabilities that you are given in the problem using notation (e.g., &amp;ldquo;$P(A|B) = 1/2$, $P(B) = 1/4$).&lt;/li>
&lt;li>Write the probability that you want to calculate using notation (e.g., we want to calculate the unconditional probability that it rains tomorrow, $P(A)$).&lt;/li>
&lt;li>Figure out how the tools we have learned allow you to utilize the probabiliies that you do know (step 2) to calculate the probabilities that you don&amp;rsquo;t know (step 3).&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;p>There are some important results that follow:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Probability of a complement&lt;/strong>: If $A$ is an event a sample space $S$,
$$
P(A) = 1 - P(A^c).
$$
Concisely, the probability of an event occuring is $1$ minus the probability of the event not occuring.&lt;/li>
&lt;li>&lt;strong>Probability of a union&lt;/strong>: For events $A$, $B$, we have
$$
P(A \cup B) = P(A) + P(B) - P(A \cap B).
$$
It&amp;rsquo;s also useful to &amp;ldquo;disjointify&amp;rdquo; $A \cup B$ into a partition ($A \cup B^c, A \cap B, A^c \cup B$) which allows us to use the second axiom and get
$$
P(A \cup B) = P(A \cup B^c) + P(A \cap B) + P(A^c \cup B).
$$&lt;/li>
&lt;li>&lt;strong>Principle of Inclusion-Exclusion (PIE)&lt;/strong>: this is a general formula for the probability of the union of $n$ events
\begin{align*}
P(\bigcup_{i=1}^n A_i) &amp;amp;= \sum_i P(A_i) - \sum_{i &amp;lt; j} P(A_i \cap A_j)\\
&amp;amp;+ \sum_{i &amp;lt; j &amp;lt; k} P(A_i \cap A_j \cap A_k) - \cdots + (-1)^{n+1} P(\bigcap_{i=1}^n A_i).
\end{align*}
Note that the formula for the probability of the union of two events is the $n=2$ case of PIE. &lt;br>
A potential workflow (that you saw on Pset 1) for the probability of an intersection, $P(A_1 \cap \cdots \cap A_n)$, is to
&lt;ul>
&lt;li>Use complementary counting and DeMorgan&amp;rsquo;s law (in that order) to turn the intersection into a union:
\begin{align*}
P(A_1 \cap \cdots \cap A_n) &amp;amp;= 1 - P((A_1 \cap \cdots \cap A_n)^c)\\
&amp;amp;= 1 - P(A_1^c \cup \cdots \cup A_n^c)
\end{align*}&lt;/li>
&lt;li>Apply PIE to the union $P(A_1^c \cup \cdots \cup A_n^c)$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;!-- TODO ADD VISUALIZATION -->
&lt;h2 id="2-conditional-probability">2. Conditional Probability&lt;/h2>
&lt;div class="alert alert-warning">
&lt;div>
&lt;p>&lt;strong>Notation note&lt;/strong>:&lt;/p>
&lt;p>We will start writing $P(A \cap B)$ as $P(A, B)$ (i.e., commas between events and intersections are equivalent).&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
&lt;p>&lt;strong>Conditional probability&lt;/strong>:&lt;/p>
&lt;p>If $A$ and $B$ are two events, then the probability that $A$ occurs &lt;strong>conditional&lt;/strong> on the fact that $B$ occurs (or &lt;em>given&lt;/em> that $B$ occurs) is notated as $P(A|B)$ and equals
$$
P(A|B) = \frac{P(A, B)}{P(B)}.
$$
All conditions go to the right of the bar symbol $|$.&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>We read $P(A|B)$ is the &amp;ldquo;probability of $A$ given $B$&amp;rdquo; or &amp;ldquo;probability of $A$ conditioned on $B$&amp;rdquo; Intuitively, we can consider that if we know $B$ occurs, $B$ basically becomes our new sample space, so we take the probability that both $A$ and $B$ occurs, $P(A, B)$, and rescale it by the probability that $B$ occurs, $P(B)$.&lt;/p>
&lt;video controls >
&lt;source src="https://srihari-ganesh.github.io/media/videos/Section2_ConditionalProbability.mp4" type="video/mp4">
&lt;/video>
&lt;p>We&amp;rsquo;re also quick to note that conditional probabilities are the same as &amp;ldquo;normal&amp;rdquo; probabilities &amp;mdash; in fact, all probabilities can be considered conditional, we just treat some conditions more implicitly than others since they are more obvious/always involved to the problem. We&amp;rsquo;ll use &lt;strong>extra conditioning&lt;/strong> to refer to problems where some conditions are always present (i.e., we never want to/don&amp;rsquo;t know how to calculate the probability of those conditionns). For example, to calculate the probability that it rains tomorrow ($A$) given that it rained today $B$, we would right $P(A|B)$. However, we are implicitly conditioning on a lot of things: that the world exists tomorrow ($W$), that I will be on Harvard campus when I check whether it rains $H$, etc. So we could incorporate these extra conditions into our problem to write the definition of &lt;strong>conditional probability with extra conditioning&lt;/strong>:
$$
P(A|B, H, W) = \frac{P(A, B | H, W)}{P(B | H, W)}
$$
As you can see, when we want certain events to be &lt;em>extra conditions&lt;/em>, they are conditions in every related probability we calculate. Each time we apply a formula for conditional probability, we have to choose whether to treat the each condition like $B$ (free to move around) or like $H$ (extra conditioning/always a condition).&lt;/p>
&lt;h2 id="3-tools-using-conditional-probability">3. Tools using Conditional Probability&lt;/h2>
&lt;div class="alert alert-warning">
&lt;div>
If you ever need to solve a problem involving a sequence of things (like a game with many turns, or a random walk, or so on) and are stuck, try &lt;strong>first-step analysis&lt;/strong>: conditioning what happens after the first step. You&amp;rsquo;ll often be able to get a recursive equation that is easier to solve.
&lt;/div>
&lt;/div>
&lt;h3 id="31-probability-of-an-intersection">3.1 Probability of an Intersection&lt;/h3>
&lt;p>For events $A, B$ we can rearrange the definition of conditional probability to find the probability of their intersection:
$$
P(A, B) = P(A) P(B | A) = P(B) P(A | B).
$$
This works for intersections of $n$ events:
$$
P(A_1, A_2, \ldots, A_n) = P(A_{i_1}) P(A_{i_2} | A_{i_1}) \cdots P(A_{i_n} | A_{i_1}, A_{i_2}, \ldots A_{i_{n-1}})
$$
where $i_1, i_2, \ldots, i_n$ is a permutation of $1, 2, \ldots, n$. Note that we can choose the conditions in any order we want, and pick the order to our best convenience &amp;mdash; for example, if you only know the unconditional probability of $A_8$, you should let $i_1 = 8$.&lt;/p>
&lt;p>The probability of an intersection &lt;em>with extra conditioning&lt;/em> is
$$
P(A, B | C) = P(A | C) P(B | A, C) = P(B | C) P(A | B, C).
$$&lt;/p>
&lt;h3 id="32-law-of-total-probability-lotp">3.2 Law of Total Probability (LOTP)&lt;/h3>
&lt;p>The &lt;strong>law of total probability (LOTP)&lt;/strong> is a clever rephrasing of the second axiom of probability (the probability of a partition is the sum of probabilities): if $A_1, A_2, \ldots, A_n$ partition the sample space, then
\begin{align*}
P(B) &amp;amp;= P(B, A_1) + P(B, A_2) + \cdots + P(B, A_n).
\end{align*}
See Figure 2.3 from Blizstein &amp;amp; Hwang below for a visualization:
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Visual diagram of the law of total probability, showing an event split up into pieces by its intersections with a partition of the sample space." srcset="
/media/images/Section2_LOTP_hu81255567074645dc13bc1b2d32e50da6_60337_e16aa315eb347d762ed01077f51a4a21.webp 400w,
/media/images/Section2_LOTP_hu81255567074645dc13bc1b2d32e50da6_60337_6c867f1081982bae899a8c3d574550e0.webp 760w,
/media/images/Section2_LOTP_hu81255567074645dc13bc1b2d32e50da6_60337_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://srihari-ganesh.github.io/media/images/Section2_LOTP_hu81255567074645dc13bc1b2d32e50da6_60337_e16aa315eb347d762ed01077f51a4a21.webp"
width="624"
height="410"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>We usually break down each of the terms using the result for the probability of an intersection &lt;a href="#31-probability-of-an-intersection">section 3.1&lt;/a>
$$
P(B) = P(B | A_1) P(A_1) + P(B | A_2) P(A_2) + \cdots + P(B | A_n) P(A_n)
$$
When you only know $B$ in terms of conditional probabilities, we can make those conditional probabilities appear through LOTP. As Joe likes to say, &lt;em>condition on what you wish you knew&lt;/em>:&lt;/p>
&lt;p>LOTP with &lt;em>extra conditioning&lt;/em> is
$$
P(B | C) = P(B | A_1, C) P(A_1 | C) + P(B | A_2, C) P(A_2 | C) + \cdots + P(B | A_n, C) P(A_n| C)
$$&lt;/p>
&lt;h3 id="33-bayes-rule">3.3 Bayes&amp;rsquo; Rule&lt;/h3>
&lt;p>&lt;strong>Bayes&amp;rsquo; Rule&lt;/strong> is also a result of the formula for the probability of an intersection:
$$
P(B|A) = \frac{P(A|B) P(B)}{P(A)}.
$$
The denominator often gets expanded out using LOTP (&lt;a href="#32-law-of-total-probability-lotp">section 3.2&lt;/a>), often with a partition containing $B$ like
$$
P(B|A) = \frac{P(A|B) P(B)}{P(A|B) P(B) + P(A|B^c) P(B^c)}.
$$
Bayes&amp;rsquo; rule is used in situations where we don&amp;rsquo;t know how to calculate the probability of $B$ given $A$, $P(B|A)$, but know how to calculate the probability of $A$ given $B$, $P(A|B)$.&lt;/p>
&lt;p>Bayes&amp;rsquo; rule with &lt;em>extra conditioning&lt;/em> is
$$
P(B | A, C) = \frac{P(A | B, C) P(B | C)}{P(A | B, C) P(B|C) + P(A|B^c, C) P(B^c|C)}
$$&lt;/p>
&lt;h2 id="4-independence">4. Independence&lt;/h2>
&lt;div class="alert alert-note">
&lt;div>
&lt;p>&lt;strong>Independence for two events&lt;/strong>&lt;/p>
&lt;p>Two events $A, B$ are independent if
$$
P(A, B) = P(A) P(B)
$$&lt;/p>
&lt;p>For $P(A), P(B) &amp;gt; 0$, this either of the following as well:
\begin{align*}
P(A|B) &amp;amp;= P(A) \text{ or }\
P(B|A) &amp;amp;= P(B)
\end{align*}&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Intuitively, independence means that information about $A$ (e.g., knowing whether $A$ occurs) gives us no information about $B$. Some&lt;/p>
&lt;ul>
&lt;li>Note that independence goes both ways &amp;mdash; if $A$ is independent of $B$, then $B$ is independent of $A$.&lt;/li>
&lt;li>If $A$ is independent of $B$, then $A$ is independent of $B^c$ and $A^c$ is independent of $B^c$.&lt;/li>
&lt;/ul>
&lt;div class="alert alert-warning">
&lt;div>
Independence and disjointness are not the same! In fact, if $A, B$ are disjoint, then if $A$ occurs we know that $B$ did not occur, so they are very &lt;em>dependent&lt;/em>.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
&lt;p>&lt;strong>Independence for many events&lt;/strong>&lt;/p>
&lt;p>A group of events $A_1, A_2, \ldots, A_n$, are independent if for any subset $A_{i_1}, A_{i_2}, \ldots, A_{i_k}$,
$$
P(A_{i_1}, A_{i_2}, \ldots, A_{i_k}) = P(A_{i_1}) P(A_{i_2}) \cdots P(A_{i_k})
$$
Note that pairwise independence (e.g., showing that $P(A_i, A_j) = P(A_i) P(A_j)$ for all $i,j$) is required, but not enough, to show that joint independence of all of the sets.&lt;/p>
&lt;/div>
&lt;/div>
&lt;h3 id="41-conditional-independence">4.1 Conditional Independence&lt;/h3>
&lt;p>&lt;strong>Conditional independence&lt;/strong> follows a similar formula: $A, B$ are conditionally independent given $C$ if
$$
P(A, B | C) = P(A|C) P(B|C).
$$
You can see how this is analogous to extra conditioning for the other results. Conditional independence of many events is similarly defined.&lt;/p>
&lt;div class="alert alert-warning">
&lt;div>
Conditional independence and independence are not the same thing, and one often exists without the other!
&lt;/div>
&lt;/div>
&lt;h2 id="5-summary">5. Summary&lt;/h2>
&lt;p>&lt;strong>Notation note&lt;/strong>: see that we use commas and intersections interchangeably (i.e., $P(A, B, C) = P(A \cap B \cap C)$).&lt;/p>
&lt;p>&lt;strong>Tips for calculating probabilities&lt;/strong>:&lt;/p>
&lt;ol>
&lt;li>Define events for every aspect of the problem (e.g., &amp;ldquo;$A$ = the event that it rains tomorrow, $B$ = the event that it rained today&amp;rdquo;)&lt;/li>
&lt;li>Write out the probabilities that you are given in the problem using notation (e.g., &amp;ldquo;$P(A|B) = 1/2$, $P(B) = 1/4$).&lt;/li>
&lt;li>Write the probability that you want to calculate using notation (e.g., we want to calculate the unconditional probability that it rains tomorrow, $P(A)$).&lt;/li>
&lt;li>Figure out how the tools we have learned allow you to utilize the probabiliies that you do know (step 2) to calculate the probabilities that you don&amp;rsquo;t know (step 3).&lt;/li>
&lt;/ol>
&lt;h3 id="51-definition-of-probability">5.1 Definition of Probability&lt;/h3>
&lt;p>&lt;strong>Axioms of probability:&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>With sample space $S$, \begin{align*}
P(S) &amp;amp;= 1\\
P(\emptyset) &amp;amp;= 0.
\end{align*}&lt;/li>
&lt;li>For $A_1, A_2, \ldots, $ that partition $B$ (this can be finite or infinite),
\begin{align*}
P(B) = \sum_{j=1}^\infty P(A_j)
\end{align*}&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Probability of a complement&lt;/strong>: For event $A$,
$$
P(A) = 1 - P(A^c)
$$&lt;/p>
&lt;p>&lt;strong>Probability of a union&lt;/strong>: For events $A$ and $B$,
\begin{align*}
P(A \cup B) &amp;amp;= P(A) + P(B) - P(A \cap B)\\ &amp;amp;= P(A \cap B^c) + P(B \cap A^c) + P(A \cap B)
\end{align*}&lt;/p>
&lt;p>&lt;strong>Principle of Inclusion-Exclusion&lt;/strong>: For events $A_1, \ldots, A_n$,
\begin{align*}
P(\bigcup_{i=1}^n A_i) &amp;amp;= \sum_i P(A_i) - \sum_{i &amp;lt; j} P(A_i \cap A_j)\\
&amp;amp;+ \sum_{i &amp;lt; j &amp;lt; k} P(A_i \cap A_j \cap A_k) - \cdots + (-1)^{n+1} P(\bigcap_{i=1}^n A_i).
\end{align*}&lt;/p>
&lt;h3 id="52-conditional-probability">5.2 Conditional Probability&lt;/h3>
&lt;p>&lt;strong>Conditional probability&lt;/strong>: For events $A$ and $B$, the probability of $A$ given $B$ (i.e., given that $B$ occured) is
\begin{align*}
P(A|B) = \frac{P(A \cap B)}{P(B)}.
\end{align*}
&lt;em>&amp;hellip;with extra conditioning&lt;/em>:
\begin{align*}
P(A|B, C) = \frac{P(A \cap B | C)}{P(B | C)}.
\end{align*}&lt;/p>
&lt;h3 id="53-conditional-probability-tools">5.3 Conditional Probability Tools&lt;/h3>
&lt;p>&lt;strong>First-step analysis&lt;/strong>: If you ever need to solve a problem involving a sequence of things (like a game with many turns, or a random walk, or so on) and are stuck, try first-step analysis: conditioning what happens after the first step. You&amp;rsquo;ll often be able to get a recursive equation that is easier to solve.&lt;/p>
&lt;p>&lt;strong>Probability of an intersection&lt;/strong>:
\begin{align*}
P(A_1, A_2, \ldots A_n) &amp;amp;= P(A_1) P(A_2 | A_1) \cdots P(A_n | A_1, \ldots, A_{n-1})\\
&amp;amp;= P(A_n) P(A_{n-1} | A_n) \cdots P(A_1 | A_2, \ldots, A_n), \\
&amp;amp;= [\text{chaining in any order that is convenient for you}].
\end{align*}
&lt;em>&amp;hellip;with extra conditioning&lt;/em>:
\begin{align*}
P(A_1, A_2, \ldots A_n | C) &amp;amp;= P(A_1 | C) P(A_2 | A_1, C) \cdots P(A_n | A_1, \ldots, A_{n-1}, C)
\end{align*}
&lt;strong>Law of Total Probability (LOTP)&lt;/strong>: for events $A_1, A_2, \ldots, A_n$ that partition $S$, we can find $P(B)$ by
\begin{align*}
P(B) &amp;amp;= P(B, A_1) + P(B, A_2) + \cdots + P(B, A_n) \\
&amp;amp;= P(B | A_1) P(A_1) + P(B | A_2) P(A_2) + \cdots + P(B | A_n) P(A_n).
\end{align*}
We pick $A_1, A_2, \ldots, A_n$ to &amp;ldquo;condition on what we wish we knew.&amp;rdquo; These are situations where you don&amp;rsquo;t know $P(B)$, but you know $P(B | A_1), (B | A_2)$, etc.&lt;/p>
&lt;p>&lt;em>&amp;hellip;with extra conditioning&lt;/em>:
\begin{align*}
P(B|C) &amp;amp;= P(B, A_1|C) + P(B, A_2|C) + \cdots + P(B, A_n|C) \\
&amp;amp;= P(B | A_1,C) P(A_1|C) + P(B | A_2,C) P(A_2|C) + \cdots + P(B | A_n,C) P(A_n|C).
\end{align*}
&lt;strong>Bayes&amp;rsquo; Rule&lt;/strong>: for events $A, B$, if we want to calculate $P(B|A)$ but can only know how to calculate $P(A|B)$,
\begin{align*}
P(B|A) &amp;amp;= \frac{P(A|B) P(B)}{P(A)}\\
&amp;amp;= \frac{P(A|B) P(B)}{P(A|B) P(B) + P(A|B^c) P(B^c)},
\end{align*}
where we commonly expand the denominator using the Law of Total Probability (LOTP).&lt;/p>
&lt;p>&lt;em>&amp;hellip;with extra conditioning&lt;/em>:
\begin{align*}
P(B|A, C) &amp;amp;= \frac{P(A|B, C) P(B|C)}{P(A|C)} \\
&amp;amp;= \frac{P(A|B, C) P(B|C)}{P(A|B, C) P(B|C) + P(A|B^c, C) P(B^c |C)}
\end{align*}&lt;/p>
&lt;h3 id="54-independence">5.4 Independence&lt;/h3>
&lt;p>&lt;strong>Independence&lt;/strong>: $A, B$ are defined to be independent if
\begin{align*}
P(A, B) = P(A) P(B).
\end{align*}
Note that if $A, B$ are independent, then so are $A, B^c$ and $A^c, B$, and $A^c, B^c$; basically any functions of $A$ and $B$ are independent.&lt;/p>
&lt;p>&lt;strong>VERY IMPORTANT&lt;/strong>: Disjointness and independence are not the same thing, and disjoint events are in fact usually independent.&lt;/p>
&lt;p>A set of events $A_1, A_2, \ldots, A_n$ is independent if any subset of the events $A_{j_1}, \ldots, A_{j_k}$ follows the equation.
\begin{align*}
P(A_{j_1}, \ldots, A_{j_k}) &amp;amp;= P(A_{j_1}) \cdots P(A_{j_k}).
\end{align*}
Basically, for any combination of independent events, we should be able to factor out the probabilities.&lt;/p>
&lt;p>&lt;strong>Conditional independence&lt;/strong>:
\begin{align*}
P(A, B | C) = P(A|C) P(B|C).
\end{align*}
&lt;strong>VERY IMPORTANT&lt;/strong>: Independence and conditional independence are not the same/do not imply each other. There is no guarantee that independent events are conditionally independent, or vice versa.&lt;/p>
&lt;!-- ## -1. Content to cover
- vandermonde's identity + birthday problem... maybe vibes but not focused. Maybe do a practice problem
- also disease testing example -->
&lt;!-- What skills to develop?
- Being able to make problem-specific calculations
- Identifying when we're independent of conditioning
- Picking what to condition on - what you wish you knew, or a single-step analysis to get you closer/recursive
- Make sure we have scattered examples as well! Maybe will work through practice problems as we go instead of leaving all for the end.
- intuitive limits of values of priors, show that extreme values stay extreme!
- maybe visualize/show bayesian updating as an average b/w prior and posterior?
--></description></item><item><title>Week 1: Counting and Definitions of Probability</title><link>https://srihari-ganesh.github.io/stat110/week1/</link><pubDate>Wed, 30 Aug 2023 00:00:00 +0000</pubDate><guid>https://srihari-ganesh.github.io/stat110/week1/</guid><description>&lt;h2 id="0-info">0. Info&lt;/h2>
&lt;ul>
&lt;li>Section date: 9/13&lt;/li>
&lt;li>Associated lectures: 9/5, 9/7&lt;/li>
&lt;li>Associated pset: Pset 1, due 9/15&lt;/li>
&lt;li>Where to find me
&lt;ul>
&lt;li>Section: Wednesdays 3-4:15pm, see section info on Canvas for location.
&lt;ul>
&lt;li>Section will always cover content for the pset due on Friday (in two days)&lt;/li>
&lt;li>Specifically, this means we&amp;rsquo;ll focus on the lectures from the previous week (six and eight days previous), and not the lecture from the day before section&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Office Hours: Wednesdays 7-9pm, see office hours info on Canvas/Google Calendar for location. I will often stay for the office hours that come right after (Wednesday 9-11pm), and occasionally may drop by at the Thursday 7:30-9:30pm office hours in the same location as well.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Syllabus clarifications
&lt;ul>
&lt;li>Problem Sets: due Fridays at 5pm. They will cover content up to the previous week (e.g., up to the lecture 8 days before the due date).&lt;/li>
&lt;li>Attendance: If your grade ends up being slightly below a grade cutoff, attendance in lecture in section may boost you over. Attendance (or lack thereof) will not be used to penalize.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Me: Srihari Ganesh (senior)
&lt;ul>
&lt;li>Concentrating in Chemical &amp;amp; Physical Biology and Math w/ a master&amp;rsquo;s in Stat&lt;/li>
&lt;li>Doing computational biology research in diffusion models for protein structure generation&lt;/li>
&lt;li>Love teaching Stat + playing IM sports on the side&lt;/li>
&lt;li>Happy to chat about everything though I&amp;rsquo;m not an expert on anything&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="1-set-theory">1. Set Theory&lt;/h2>
&lt;div class="alert alert-note">
&lt;div>
&lt;p>A &lt;strong>set&lt;/strong> is an unordered collection of unique items. For example, $A = \{ 8, 1, 2 \}$ is a set with items (&lt;strong>elements&lt;/strong>) $8$, $1$, and $2$.&lt;/p>
&lt;ul>
&lt;li>Sets are unordered, so $\{8, 1, 2 \} = \{2, 8, 1\}$.&lt;/li>
&lt;li>Sets contain unique elemnts, so $\{8, 1, 2, 1\}$ is NOT a set.&lt;/li>
&lt;li>Sets are a collection of any type of item, so $\{A, B, C\}$, $\{\text{car, cow, walnut}\}$, and $\{$â¤ï¸, ðŸ‘¨â€ðŸ«, â³$\}$ are all sets.&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;h3 id="11-definitions">1.1 Definitions&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>$A$ is a &lt;strong>subset&lt;/strong> of $B$ (notated $A \subset B$ or $A \subseteq B$) if every element of $A$ is also an element of $B$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;strong>empty set&lt;/strong> (notated $\emptyset$) is the set with no elements, $\{\}$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;strong>union&lt;/strong> (notated $A \cup B$) is the set of all elements that are in $A$ or $B$ (or both).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;strong>intersection&lt;/strong> (notated $A \cap B$) is the set of all elements that are in both $A$ and $B$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$A$ and $B$ are &lt;strong>disjoint&lt;/strong> if $A$ and $B$ share no elements (notated $A \cap B = \emptyset$)&lt;/p>
&lt;ul>
&lt;li>A collection of sets $A_1, \ldots, A_n$ are &lt;strong>disjoint&lt;/strong> if no pair of sets shares any elements ($A_i \cap A_j = \emptyset$ for all $i, j$)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>A collection of sets $B_1, B_2, \ldots, B_n$ are a &lt;strong>partition&lt;/strong> of $B$ if&lt;/p>
&lt;ul>
&lt;li>$B_1, B_2, \ldots, B_n$ are disjoint, and&lt;/li>
&lt;li>$B_1 \cup B_2 \cup \cdots \cup B_n = B$.&lt;/li>
&lt;/ul>
&lt;p>Intuitively, $B_1, B_2, \ldots, B_n$ are (non-overlapping) puzzle pieces that form the the puzzle, $B$, when put together.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;strong>complement&lt;/strong> of a set $A$ (notated $A^c$) is the set of all elements not in $A$&lt;/p>
&lt;ul>
&lt;li>Complements have to be taken relative to some superset $S$ (notated $A \subset S$). We think of this set as the &amp;ldquo;universe&amp;rdquo; that $A$ lives in, and is usually implied by context.&lt;/li>
&lt;li>ex. Let $S = \{1, 2, 3 \}, A = \{1, 3\}$. Then $A^c = \{2\}$.&lt;/li>
&lt;li>Note that $A$ and $A^c$ partition $S$.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>The &lt;strong>difference&lt;/strong> between two sets $B \setminus A$ is the set of all elements in $B$ which are not in $A$.&lt;/p>
&lt;ul>
&lt;li>Note that $B \cap A$, $B \setminus A$ partition $B$.&lt;/li>
&lt;li>An equivalent notation is $B \setminus A = B \cap A^c$.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>The &lt;strong>cardinality&lt;/strong> of a set, |A|, indicates the size of the set. For finite sets, it is the number of elements in the set.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We notate set membership in the following way: letting $A = \{8, 1, 2\}$,&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;$2$ is in $A$&amp;rdquo; is notated $2 \in A$.&lt;/li>
&lt;li>&amp;ldquo;$0$ is not in $A$&amp;rdquo; is notated $0 \notin A$.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="12-verbal-understanding">1.2 Verbal Understanding&lt;/h3>
&lt;p>We want to think about basic set operations in words.&lt;/p>
&lt;ul>
&lt;li>$x \in A$ reads as &amp;ldquo;$x$ is in $A$&amp;rdquo;.
&lt;ul>
&lt;li>We tend to work with sets by thinking about whether some variable or number is in the (e.g., whether or not $x \in A$) instead of just looking at the set written out like $A = \{8, 1, 2\}$.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>$A \cup B$ reads as &amp;ldquo;$A$ &lt;em>or&lt;/em> $B$&amp;rdquo;. So we can say $x \in A \cup B$ intuitively reads as &amp;ldquo;$x$ is in $A$ &lt;strong>or&lt;/strong> $x$ is in $B$&amp;rdquo;.
&lt;ul>
&lt;li>Be careful to note that we are using the inclusive or, so $A \textit{ or } B$ means $A$, $B$, or both.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>$A \cap B$ reads as &amp;ldquo;$A$ &lt;em>and&lt;/em> $B$&amp;rdquo;. So $x \in A \cap B$ reads as &amp;ldquo;$x$ is in $A$ &lt;strong>and&lt;/strong> $x$ is in $B$&amp;rdquo;.&lt;/li>
&lt;li>$A^c$ reads as &amp;ldquo;not $A$&amp;rdquo;, so $x \in A^c$ reads as &amp;ldquo;$x$ is not in $A$&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>We can apply this so see that the two versions of the set difference are equivalent. $x \in B \setminus A$ reads as &amp;ldquo;$x$ is in $B$ but not in $A$&amp;rdquo;, while $x \in B \cap A^c$ reads as &amp;ldquo;$x$ is in B and in $A^c$ (i.e., not in $A$).&amp;rdquo;&lt;/p>
&lt;p>What if we have multiple operations in the same expression?&lt;/p>
&lt;ul>
&lt;li>$x \in (A \cap B)^c$ reads as &amp;ldquo;$x$ is not in both $A$ and $B$&amp;rdquo;. This means that either $x$ is not in $A$ or $x$ is not in $B$, so $x \in A^c \cup B^c$.&lt;/li>
&lt;li>$x \in (A \cup B)^c$ read as &amp;ldquo;$x$ is not in $A$ or $B$&amp;rdquo;. This means that $x$ is not in $A$ and $x$ is not in $B$, so $x \in A^c \cap B^c$.
We see in the next section that these statements are essentially DeMorgan&amp;rsquo;s laws.&lt;/li>
&lt;/ul>
&lt;h3 id="13-demorgans-laws">1.3 DeMorgan&amp;rsquo;s Laws&lt;/h3>
&lt;div class="alert alert-note">
&lt;div>
&lt;strong>DeMorgan&amp;rsquo;s Laws&lt;/strong>
\begin{align}
(A \cap B)^c &amp;amp;= A^c \cup B^c \\
(A \cup B)^c &amp;amp;= A^c \cap B^c
\end{align}
&lt;/div>
&lt;/div>
&lt;p>By talking through the expressions, you should eventually be able to convince yourself that the laws are true.&lt;br>
These videos also walk through the process visually:
&lt;video controls >
&lt;source src="https://srihari-ganesh.github.io/media/videos/Section1_DeMorgan1.mp4" type="video/mp4">
&lt;/video>
&lt;video controls >
&lt;source src="https://srihari-ganesh.github.io/media/videos/Section1_DeMorgan2.mp4" type="video/mp4">
&lt;/video>
&lt;/p>
&lt;h2 id="2-counting">2. Counting&lt;/h2>
&lt;h3 id="20-some-useful-problem-solving-strategies-lifted-from-95-lecture">2.0 Some useful problem-solving strategies (lifted from 9/5 lecture)&lt;/h3>
&lt;ul>
&lt;li>Try simple/extreme cases (i.e., set $n$ to be a small number and brute-force)
&lt;ul>
&lt;li>For each tool below, we&amp;rsquo;ll motivate it with an example. You can click the drop-down to view the example.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Give objects of interest &lt;em>names&lt;/em> or &lt;em>ID numbers&lt;/em>&lt;/li>
&lt;li>Draw a diagram&lt;/li>
&lt;li>Make a story&lt;/li>
&lt;/ul>
&lt;h3 id="21-multiplication-rule">2.1 Multiplication Rule&lt;/h3>
&lt;p>&lt;strong>How many different combinations can you make?&lt;/strong>&lt;br>
&lt;details class="spoiler " id="spoiler-4">
&lt;summary>&lt;ins>Click for example&lt;/ins>&lt;/summary>
&lt;p>&lt;p>If an ice cream parlor has $4$ different flavors and $3$ different cup sizes, there are $4 \times 3 = 12$ different orders I could make.&lt;/p>
&lt;p>This example exhibits all of the above problem-solving strategies. We took the general multiplication rule (see general statement below) and, made a story about an ice cream parlor, and set $a = 4$, $b=3$. We drew a diagram (the tree below), and gave the objects (flavors and cup sizes) names in that diagram.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Tree diagram of the ice cream parlor example, combining four ice cream flavors and 3 cup sizes to yield 4 times 3 = 12 possible orders." srcset="
/media/images/Section1_Tree_hu9544750ee73ba0725668d11c52a82e97_147874_29105694be846087f9bc432364e890bc.webp 400w,
/media/images/Section1_Tree_hu9544750ee73ba0725668d11c52a82e97_147874_9b2c3ae9f8dc6a45b203c506f9118536.webp 760w,
/media/images/Section1_Tree_hu9544750ee73ba0725668d11c52a82e97_147874_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://srihari-ganesh.github.io/media/images/Section1_Tree_hu9544750ee73ba0725668d11c52a82e97_147874_29105694be846087f9bc432364e890bc.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;/p>
&lt;/details>&lt;/p>
&lt;p>&lt;ins>General statement&lt;/ins>: Say the outcome of a full experiment is given by the outcomes of two-subexperiments, $A$ and $B$. If sub-experiment $A$ has $a$ possible outcomes and sub-experiment $B$ has $b$ possible outcomes, then the full experiment has $a \times b$ possible outcomes.&lt;/p>
&lt;ul>
&lt;li>Note here that this will work as long as the outcome of $A$ doesn&amp;rsquo;t change the &lt;em>number&lt;/em> of possible outcomes of $B$, even if $A$ changes &lt;em>which&lt;/em> outcomes are possible for $B$.&lt;/li>
&lt;/ul>
&lt;h3 id="22-factorial">2.2 Factorial&lt;/h3>
&lt;p>&lt;strong>How many ways can you order $n$ distinct items?&lt;/strong>&lt;br>
&lt;details class="spoiler " id="spoiler-5">
&lt;summary>&lt;ins>Click for example&lt;/ins>&lt;/summary>
&lt;p>How many ways can $n=52$ card deck of cards be shuffled? I have $52$ options for the first card, then $52-1 = 51$ options for the second card, $52-2 = 50$ options for the third card, and so on. The total number of ways is thus $$52 \times 51 \times 50 \times \cdots \times 2 \times 1.$$&lt;/p>
&lt;/details>&lt;/p>
&lt;p>&lt;ins>General statement&lt;/ins>: We use the factorial, $n!$, as a shorthand for this specific application of the multiplication rule. We have $n$ choices for the first item; we can then pick $(n-1)$ choices for the second item, and so on, giving
$$
n! = n \times (n-1) \times (n-2) \cdots \times 2 \times 1.
$$&lt;/p>
&lt;h3 id="23-permutations">2.3 Permutations&lt;/h3>
&lt;p>&lt;strong>How many ways can you choose an ordered collection of $k$ distinct items from a set of $n$ distinct items?&lt;/strong>&lt;br>
&lt;details class="spoiler " id="spoiler-6">
&lt;summary>&lt;ins>Click for example&lt;/ins>&lt;/summary>
&lt;p>I want to take a $k=3$ week trip in New England, spending each week in a different state. New England has $n=6$ states, so using the multiplication rule, I have $6 \times 5 \times 4 = 120$ possible trips I can go on.&lt;/p>
&lt;/details>
&lt;ins>General statement&lt;/ins>: Using the multiplication rule, the solution is
$$
n \times (n-1) \times \cdots \times (n-k+1) = \frac{n!}{(n-k)!}.
$$&lt;/p>
&lt;div class="alert alert-warning">
&lt;div>
&lt;p>Be careful with off-by-one errors when you&amp;rsquo;re listing consecutive integers.&lt;/p>
&lt;p>For a list of $k$ consecutive integers, the first and last numbers should have a difference of $k-1$.&lt;/p>
&lt;p>For example, the list &amp;ldquo;$3, 4, 5, 6$&amp;rdquo; has $4$ items, so the difference between the first and last numbers if $6-3 = 3 = 4-1$.&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>How many ways can you order a set of $n$ items, where some items are repeated?&lt;/strong>&lt;br>
&lt;details class="spoiler " id="spoiler-8">
&lt;summary>&lt;ins>Click for example&lt;/ins>&lt;/summary>
&lt;p>&lt;p>How many anagrams (orderings/permutations) are there of the word &amp;ldquo;BANANA&amp;rdquo;? In other words, how many $n=6$ letter words have 3 A&amp;rsquo;s, 1 B, and 2 N&amp;rsquo;s?&lt;/p>
&lt;p>If we treated the letters as distinct, there would be $6!$ ways to order them. However, the 3 A&amp;rsquo;s are identical, so we are overcounting. For example, if we artificially distinguish the A&amp;rsquo;s, we see that&lt;br>
&amp;ldquo;B&lt;em>A&lt;/em>N&lt;strong>A&lt;/strong>N&lt;ins>A&lt;/ins>&amp;rdquo;, &amp;ldquo;B&lt;strong>A&lt;/strong>N&lt;em>A&lt;/em>N&lt;ins>A&lt;/ins>&amp;rdquo;, &amp;ldquo;B&lt;ins>A&lt;/ins>N&lt;strong>A&lt;/strong>N&lt;em>A&lt;/em>&amp;rdquo;, &amp;ldquo;B&lt;ins>A&lt;/ins>N&lt;em>A&lt;/em>N&lt;strong>A&lt;/strong>&amp;rdquo;, &amp;ldquo;B&lt;strong>A&lt;/strong>N&lt;ins>A&lt;/ins>N&lt;em>A&lt;/em>&amp;rdquo;, and &amp;ldquo;B&lt;em>A&lt;/em>N&lt;ins>A&lt;/ins>N&lt;strong>A&lt;/strong>&amp;rdquo;&lt;br>
are all counted as different words. This means there we are overcounting the orderings of the 3 A&amp;rsquo;s by $3!$, so we can divide to get $6!/3!$.&lt;br>
Similarly, we are overcounting the orderings of the 2 N&amp;rsquo;s by $2!$. There is only one B, so we are not overcounting that. This gives a final answer of $\frac{6!}{3!2!} = 120$ orderings.&lt;/p>
&lt;/p>
&lt;/details>&lt;/p>
&lt;p>&lt;ins>General statement&lt;/ins>: say we have $n$ items total with $m$ types, made up of $n_1$ items of type 1, $n_2$ items of type 2, and so forth, with $n = \sum_{i=1}^m n_i$. Then the number of permutations is
\begin{equation}
\frac{n!}{n_1! n_2! \cdots n_m!}.
\end{equation}&lt;/p>
&lt;h3 id="24-binomial-coefficient">2.4 Binomial Coefficient&lt;/h3>
&lt;p>&lt;strong>How many ways can you choose an unordered group of $k$ items, without replacement, from a set of $n$ distinct items?&lt;/strong>&lt;br>
In order words, if a set has $n$ elements, how many subsets with exactly $k$ elements does it have?&lt;/p>
&lt;details class="spoiler " id="spoiler-9">
&lt;summary>&lt;ins>Click for example&lt;/ins>&lt;/summary>
&lt;p>&lt;p>From my $n=4$ nuclear family members, how many ways can I choose $k=2$ of them to go on an all-expenses paid trip to Cambridge, Massachusetts with me?&lt;/p>
&lt;p>I can use the multiplication rule, so I have $4$ options for the first family member and $3$ options for the second. However, I don&amp;rsquo;t care about the order, so I can divide by $2!$ to get $\frac{4 \times 3}{2!} = 6$ unordered groups of $2$ family members.&lt;/p>
&lt;/p>
&lt;/details>
&lt;p>&lt;ins> General statement&lt;/ins>: &lt;a href="#23-permutations">Using our previous permutation result&lt;/a>, we can first pick $k$ items in order: $n \times (n-1) \times \cdots \times (n-k+1) = \frac{n!}{(n-k)!}$.&lt;/p>
&lt;p>Since we don&amp;rsquo;t care about the order, we can then correct our overcounting by dividing by $k!$ to get the answer, which is called the &lt;strong>binomial coefficient&lt;/strong>:
\begin{equation}
\binom{n}{k} = \frac{n!}{k!(n-k)!}.
\end{equation}&lt;/p>
&lt;h3 id="25-counting-subsets">2.5 Counting Subsets&lt;/h3>
&lt;p>&lt;strong>How many ways can you select an unordered group of items (of any size, including $0$), without replacement, from a set of $n$ distinct items?&lt;/strong>&lt;br>
Alternatively worded, given a set of size $n$, how many different subsets can you come up with (including the empty set)?&lt;/p>
&lt;p>The first item of the set is either in the the group or not, so there are 2 possibilities. This applies for each item in the set &amp;mdash; it is either in the group or not. We can apply the multiplication rule to get the that the number of possible groups is
\begin{equation}
2 \times 2 \times \cdots \times 2 = 2^n.
\end{equation}&lt;/p>
&lt;h3 id="26-bose-einstein">2.6 Bose-Einstein&lt;/h3>
&lt;p>&lt;strong>How many ways can you choose an unordered group of $k$ items, with replacement, from a set of $n$ items?&lt;/strong>&lt;/p>
&lt;details class="spoiler " id="spoiler-10">
&lt;summary>&lt;ins>Click for example&lt;/ins>&lt;/summary>
&lt;p>&lt;p>At a donut shop with $n=3$ different flavors, how many ways distinct orders of $k=5$ donuts can I make?&lt;/p>
&lt;p>Let&amp;rsquo;s start with smaller values of $n$ and up the complexity. With only $n=1$ flavor, there&amp;rsquo;s only one possible order (all donuts of one flavor). With $n=2$ flavors (e.g., frosted and glazed), the order is uniquely determined by how many frosted donuts there are; for example, if we have $3$ frosted donuts, we know there must be $5-3$ glazed donuts. In the example below, we say that the donuts to the left of the divider are frosted, and those to the right are glazed.&lt;/p>
&lt;video controls >
&lt;source src="https://srihari-ganesh.github.io/media/videos/Section1_BE1.mp4" type="video/mp4">
&lt;/video>
&lt;p>For larger $n$, we follow a similar idea and count in a clever way. Your order can be uniquely represented by how many donuts of each flavor you buy, so we can think of placing dividers between donuts to uniquely represent our order. Each &amp;ldquo;box&amp;rdquo; created by the dividers represents a flavor: those to the left of the first divider are frosted, between the first and second divider are glazed, between the second and third divider are jam, etc.&lt;/p>
&lt;video controls >
&lt;source src="https://srihari-ganesh.github.io/media/videos/Section1_BE2.mp4" type="video/mp4">
&lt;/video>
&lt;p>Note that we need $4-1 = 3$ dividers to create $4$ categories. So how do we count ways to put $2$ dividers among $5$ donuts? We&amp;rsquo;ll count by treating dividers as distinguishable, then correct for the overcounting later. We have $5+1=6$ options for where to put the first divider (to the left of the first donut, between the first and second donut, etc.). The second divider has $5+1+1=7$ optinos, since there are now $6$ items ($5$ donuts, $1$ divider) that we can go between or to the left/right of. The third divider has $5+2+1=8$ options. By this pattern, we have $6 \times 7 \times 8$ ways to place dividers. However, the dividers themselves don&amp;rsquo;t tell us anything about how the donuts are divied up - only their locations - so we don&amp;rsquo;t care about the order they were placed. Thus, we divide by $3!$ ways to order the dividers to get $\frac{6 \times 7 \times 8}{3!} = \binom{8}{3}$.&lt;/p>
&lt;p>Another way to think about this is that we have $5 + (4-1) = 8$ &amp;ldquo;slots&amp;rdquo; (donuts and dividers) in a row, and we need to pick out the locations of the $3$ dividers. We can use the binomial coefficient to do this in $\binom{8}{3}$ ways.&lt;/p>
&lt;/p>
&lt;/details>
&lt;p>I encourage you to check out the example above for much of the derivation of the Bose-Einstein counting method.&lt;/p>
&lt;p>&lt;ins>General statement&lt;/ins>: We are trying to split the $k$ items into $n$ categories, which we can do by placing $n-1$ dividers between the $k$ items. We can re-frame this problem as selecting the locations of $n-1$ dividers from $(n-1)+k$ slots (items + dividers), which means our solution is $$\binom{n-1+k}{n-1} = \binom{n-1+k}{k}.$$&lt;/p>
&lt;p>Note: Bose-Einstein is a bit of a &amp;ldquo;big hammer&amp;rdquo; &amp;mdash; it can solve some pretty complicated problems, but also some simpler ones. You should make sure you have exhausted your other tools, and that your problem matches the &amp;ldquo;unordered, with replacement&amp;rdquo; requirement before trying this out.&lt;/p>
&lt;h2 id="3-definitions-of-probability">3. Definitions of Probability&lt;/h2>
&lt;ul>
&lt;li>The &lt;strong>sample space&lt;/strong> $S$ is the set of all possible &lt;strong>outcomes&lt;/strong> of an experiment (i.e., each element of $S$ is a unique outcome).
&lt;ul>
&lt;li>After an experiment is completed, exactly one of the outcomes will have occurred.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>An &lt;strong>event&lt;/strong> $A$ is any subset of $S$ ($A \subset S$) - anything that we could say either &amp;ldquo;happened&amp;rdquo; or &amp;ldquo;didn&amp;rsquo;t happen&amp;rdquo; once the experiment takes place. We calculate the probabilities of events (e.g., the probability that an event $A$ happens).
&lt;ul>
&lt;li>After an experiment is completed, every event will have
&lt;ul>
&lt;li>&amp;ldquo;Happened&amp;rdquo; or &amp;ldquo;happened&amp;rdquo; if it contains the outcome which actually occurred.&lt;/li>
&lt;li>&amp;ldquo;Not happened&amp;rdquo; or &amp;ldquo;not occurred&amp;rdquo; if it does not contain the outcome which actually occured.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="31-naive-definition-of-probability">3.1 Naive Definition of Probability&lt;/h3>
&lt;details class="spoiler " id="spoiler-11">
&lt;summary>&lt;ins>Click for example&lt;/ins>&lt;/summary>
&lt;p>&lt;p>When rolling a standard die, the sample space is typically denoted by $S = \{1, 2, 3, 4, 5, 6\}$, where each element of $S$ is a possible outcome.&lt;/p>
&lt;p>Possible events could be rolling a $1$ (the event being $A = \{1\}$), rolling an odd number, $B = \{1, 3, 5\}$, or rolling a small number $C = \{1, 2, 3\}$.&lt;/p>
&lt;p>For a fair die, you might intuitively know that the probability of $A$ is $1/6$, the probability of $B$ is $3/6=1/2$, and the probability of $C$ is $3/6=1/2$. Also see that it&amp;rsquo;s possible that the events $A, B, C$ all occur, even though only one outcome actually occur.&lt;/p>
&lt;video controls >
&lt;source src="https://srihari-ganesh.github.io/media/videos/Section1_Events.mp4" type="video/mp4">
&lt;/video>
&lt;/p>
&lt;/details>
&lt;div class="alert alert-note">
&lt;div>
&lt;strong>Naive definition of probability&lt;/strong>:&lt;br>
We assume that there are a finite number of outcomes (the sample space, $S$, is finite), and that each individual outcome has an equal probability of occuring. Then the probability of an event $A$ is.
$$
P_{\text{naive}}(A) = \frac{\text{# of outcomes in $A$}}{\text{# of outcomes in $S$}} = \frac{|A|}{|S|}.
$$
&lt;/div>
&lt;/div>
&lt;p>Limitations:&lt;/p>
&lt;ul>
&lt;li>Assumes that all outcomes are equally likely
&lt;ul>
&lt;li>Shaky definition of what &amp;ldquo;equally likely&amp;rdquo; means because we can arbitrarily construct the outcomes.&lt;/li>
&lt;li>&lt;em>ex.&lt;/em> Say the weather tomorrow has two possible outcomes: $\{\text{precipitation}, \text{no precipitation}\}$. By the naive definition, there&amp;rsquo;s a $50%$ chance of no precipitation.&lt;br>
Alternatively, I could have said the possible outcomes are $\{\text{rain}, \text{sleet}, \text{hail}, \text{snow}, \text{no precipitation}\}$. Then there&amp;rsquo;s only a $20%$ chance of no precipitation&amp;hellip; so which is it?&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Assumes the sample space is finite
&lt;ul>
&lt;li>What if the sample space is of possible temperatures? There are infinitely many possible temperatures, they can&amp;rsquo;t each have a $1/\infty$ probability.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="32-general-definition-of-probability">3.2 General Definition of Probability&lt;/h3>
&lt;div class="alert alert-note">
&lt;div>
&lt;p>&lt;strong>Definition of probability&lt;/strong>:&lt;br>
There are just two axioms (rules that probabilities have to follow):&lt;/p>
&lt;ol>
&lt;li>$P(S) = 1, P(\emptyset) = 0.$&lt;/li>
&lt;li>If events $A_1, A_2, \ldots$ are disjoint, then $$
P\left( \bigcup_{j=1}^\infty A_j\right) = \sum_{j=1}^\infty P(A_j).
$$&lt;/li>
&lt;/ol>
&lt;p>In other words, if $A_1, A_2, \ldots$ partition some event $B$, then $P(B) = \sum_{j=1}^\infty P(A_j)$.&lt;/p>
&lt;/div>
&lt;/div>
&lt;h4 id="321-probability-of-complements">3.2.1 Probability of Complements&lt;/h4>
&lt;p>Let&amp;rsquo;s say we know the probability of some event $A$. Then $$P(A^c) = 1 - P(A).$$ This follows directly from the axioms of probability: since $A^c, A$ partition the sample space $S$, we know $P(A) + P(A^c) = P(S) = 1$. When you&amp;rsquo;re asked to calculate the probability of events in the form of &amp;ldquo;at least&amp;rdquo; or &amp;ldquo;at most&amp;rdquo;, the probability of the complement may sometimes be simpler to calculate.&lt;/p>
&lt;h4 id="322-principle-of-inclusion-exclusion-pieprobability-of-unions">3.2.2 Principle of Inclusion-Exclusion (PIE)/Probability of unions&lt;/h4>
&lt;p>Say we have two events (not necessarily disjoint) $A$ and $B$. We can partition $A \cup B$ into $A \setminus B, A \cap B, B \setminus A$.
\begin{align*}
P(A \cup B) &amp;amp;= P(A \setminus B) + P(A \cap B) + P(B \setminus A)\\
P(A \cup B) &amp;amp;= P(A \setminus B) + P(A \cap B) + P(B \setminus A) + P (A \cap B) - P(A \cap B)\\
P(A \cup B) &amp;amp;= P(A) + P(B) - P(A \cap B),
\end{align*}
where we apply the second axiom of probability using the fact that $A \setminus B, A \cap B$ partition $A$ and the fact that $B \setminus A, A \cap B$ partition $B$.&lt;/p>
&lt;p>This extends to finding the probability of the union of any $n$ events, which is called the &lt;strong>Principle of Inclusion-Exclusion (PIE)&lt;/strong>
\begin{align*}
P(A_1 \cup A_2 \cup \cdots \cup A_n) &amp;amp;= \sum_{i=1}^n P(A_i) - \sum_{i&amp;lt;j} P(A_i \cap A_j) + \sum_{i &amp;lt; j &amp;lt; k} P(A_i \cap A_j \cap A_k) \\
&amp;amp;- \cdots + (-1)^{n-1} P(A_1 \cap A_2 \cap \cdots \cap A_n).
\end{align*}&lt;/p>
&lt;p>We are a bit careless with notation in the sums: $\sum_{i&amp;lt;j}$ means that we sum over every (unordered) pair of events. This formula is better remembered in words: add up the probabilities of all individual events, subtract the probabilities of every pair, add back the probabilities of every triple, etc.; remember that you start positive, then alternate signs.&lt;/p>
&lt;p>PIE is another tool that is a big hammer: it will always work if you&amp;rsquo;re finding the probability of a union (the probability that at least one event occurs), but it is unwieldy for most problems and should be one of your last resorts.&lt;/p>
&lt;h2 id="4-summary">4. Summary&lt;/h2>
&lt;h3 id="41-set-theory">4.1 Set Theory&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Sets&lt;/strong>: unordered collections of items&lt;/li>
&lt;li>Important set operations: intersection, union, complement, difference, cardinality&lt;/li>
&lt;li>Important properties: set membership, subsets, disjoint sets, partitions&lt;/li>
&lt;li>Theorems: DeMorgan&amp;rsquo;s laws&lt;/li>
&lt;/ul>
&lt;h3 id="42-counting">4.2 Counting&lt;/h3>
&lt;p>All of our counting is driven by the multiplication rule. Here&amp;rsquo;s what we&amp;rsquo;ve built from that, working from a set of $n$ distinct items:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>select how many items?&lt;/th>
&lt;th>ordered or unordered?&lt;/th>
&lt;th>with or without replacement?&lt;/th>
&lt;th>solution&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>take all $n$ items,&lt;/td>
&lt;td>order the items,&lt;/td>
&lt;td>without replacement&lt;/td>
&lt;td>n!&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>select $k$ items,&lt;/td>
&lt;td>ordered,&lt;/td>
&lt;td>without replacement&lt;/td>
&lt;td>$\frac{n!}{(n-k)!}$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>select $k$ items,&lt;/td>
&lt;td>unordered,&lt;/td>
&lt;td>without replacment&lt;/td>
&lt;td>$\binom{n}{k}$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>select any number of items,&lt;/td>
&lt;td>unordered,&lt;/td>
&lt;td>without replacement&lt;/td>
&lt;td>$2^n$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>select $k$ items,&lt;/td>
&lt;td>unordered,&lt;/td>
&lt;td>with replacement&lt;/td>
&lt;td>$\binom{n+k-1}{k}$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>select $k$ items,&lt;/td>
&lt;td>ordered,&lt;/td>
&lt;td>with replacement&lt;/td>
&lt;td>$n^k$&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>You may also have seen this sampling table (below) in lecture (for counting the numbers of ways to draw a sample of $k$ items from $n$ distinct items). I suggest breaking down every counting problem into whether order matters and whether you are sampling with replacement, and trying out the corresponding approach in the table.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>Order matters&lt;/th>
&lt;th>Order doesn&amp;rsquo;t matter&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>With replacement&lt;/td>
&lt;td>$n^k$&lt;/td>
&lt;td>$\binom{n+k-1}{k}$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Without replacement&lt;/td>
&lt;td>$\frac{n!}{(n-k)!}$&lt;/td>
&lt;td>$\binom{n}{k}$&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>We also talked about the permutation problem with $n$ items that aren&amp;rsquo;t necessarily distinct (order all $n$ items without replacement), where we compensate for overcounting after the fact: $$\frac{n!}{n_1! n_2! \cdots n_m!}.$$&lt;/p>
&lt;h3 id="43-definitions-of-probability">4.3 Definitions of Probability&lt;/h3>
&lt;p>&lt;strong>Naive probability&lt;/strong>: probably the most intuitive (and yet very flawed) way to define probability: the probability is proportional to the number of outcomes. For example, there are 3 ways to roll an even number on a die, so by this definition, there is a $3/6 = 1/2$ probability of rolling an even number.&lt;/p>
&lt;p>&lt;strong>(Non-naive) probability&lt;/strong>: given by two axioms:&lt;/p>
&lt;ol>
&lt;li>$P(S) = 1$&lt;/li>
&lt;li>$P\left(\bigcup_{j=1}^\infty A_j \right) = \sum_{j=1}^\infty P(A_j)$ for $A_1, A_2, \ldots$ disjoint.&lt;/li>
&lt;/ol>
&lt;p>The principle of inclusion-exclusion and the probability of complements follow from the axioms.&lt;/p>
&lt;h2 id="5-practice-problems">5. Practice Problems&lt;/h2>
&lt;p>&lt;a href="https://srihari-ganesh.github.io/uploads/stat110/Section%201%20Practice%20Problems.pdf" target="_blank">Practice Problem PDF&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://srihari-ganesh.github.io/uploads/stat110/Section%201%20Solutions.pdf" target="_blank">Practice Problem Solutions PDF&lt;/a>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>I am interested in five subjects (statistics, math, computer science, chemistry, and biology) and am deciding between 100, 102, 110, and 111 in each department (e.g., my options are Stat 100, Stat 102, Stat 110, Stat 111, Math 100, Math 102, etc.). Assume unless stated otherwise that each class (or set of classes) is equally likely to be chosen if possible.&lt;/p>
&lt;ol>
&lt;li>How many different schedules of four courses can I take?&lt;/li>
&lt;li>I want to send my friend a text of my 4-class schedule. My text will look be a list like &amp;ldquo;Chemistry 101, Stat 110, Biology 111, Math 101&amp;rdquo;, which is considered a different text from &amp;ldquo;Stat 110, Chemistry 101, Biology 111, Math 101&amp;rdquo;. How many different such texts could I send?&lt;/li>
&lt;li>If I take 5 courses, what is the probability that I take exactly 1 course from each department?&lt;/li>
&lt;li>My advisor wants to know that I have backup plans, so they ask me to send 2 schedules with 4 courses each, where the schedules can have no overlap. How many such sets of two schedules can I send my advisor?&lt;/li>
&lt;li>After I finalize my schedule, my advisor now wants to know how many classes I&amp;rsquo;m taking in each subject, so I send them a list that follows the following format of the following example (with the subjects always in this order):&lt;br>
&lt;br>
[Statistics: 2, Math: 0, Computer Science: 1, Chemistry: 1, Biology: 1]&lt;br>
&lt;br>
How many such lists can I send for a 4-class schedule?&lt;/li>
&lt;li>If I take 6 courses, what is the probability that there&amp;rsquo;s at least 1 subject in which I am not taking any courses? Solve this problem in two ways.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>&lt;em>(Problem statement taken from Rachel Li and Ginnie Ma&amp;rsquo;s notes)&lt;/em> Hockey Stick Identity: show using a story proof that
$$
\sum_{j=k}^n \binom{j}{k} = \binom{n+1}{k+1}.
$$
Hint: Imagine arranging a group of people by age, and then think about the oldest person in a chosen subgroup.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Use problem 1.4 to construct a story proof for the following identity (assuming $n \ge 2k$). Recall that in problem 1.4, my advisor asked me to make 2 (non-overlapping) schedules with 4 courses each.
$$
\binom{n}{2k} \binom{2k}{k} = \binom{n}{k}\binom{n-k}{k}
$$&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="51-extra-practice-problems-if-you-have-time-during-section">5.1 Extra practice problems (if you have time during section)&lt;/h3>
&lt;p>&lt;em>Taken from the section materials of Rachel Li and Ginnie Ma (&amp;lsquo;23)&lt;/em>&lt;/p>
&lt;ol start="4">
&lt;li>
&lt;p>(&lt;strong>Lattice Walks&lt;/strong>) You start at the origin of a grid. Assuming you can only move up or to the right one unit at a time, how many different paths exist between you and position $(10, 10)$? Next, assume you are in a 3D-space. How many different paths exist between you and position $(10, 10, 10)$? Last, say your motions are defined by a 2-dimensional random walk: where you either walk right or up one unit with equal probability. After 20 steps, what is the probability that you are at position $(10, 10)$?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>(&lt;strong>Coin Toss Gambling&lt;/strong>, &lt;em>Question Credit: Zhou, 2008&lt;/em>) Two gamblers are playing a coin toss game. Gambler A has $(n + 1)$ fair coins. Gambler B has $n$ fair coins. What is the probability that A will have more heads than B if they all flip their coins? &lt;br>
&lt;em>Hint: What are the possible results (events) if we compare the number of heads in Aâ€™s first $n$ coins with Bâ€™s $n$ coins? By making the number of coins equal, we can take advantage of symmetry. For each event, what will happen if Aâ€™s last coin is a head? Or Tails?&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>(&lt;strong>Teenager Steps&lt;/strong>) A teenage boy recently went through his first growth spurt, and can now walk up stairs one or two stairs at a time. How many different ways are there for him to ascend to the top of a staircase with $n$ stairs? &lt;br>
&lt;em>Hint: start with small $n$. The solution should look familiar!&lt;/em>&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>Stat 110 Section Notes</title><link>https://srihari-ganesh.github.io/projects/stat110/</link><pubDate>Tue, 30 Aug 2022 00:00:00 +0000</pubDate><guid>https://srihari-ganesh.github.io/projects/stat110/</guid><description/></item><item><title>A Local Existence and Uniqueness Theorem for First Order Differential Equations</title><link>https://srihari-ganesh.github.io/projects/math22b/</link><pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate><guid>https://srihari-ganesh.github.io/projects/math22b/</guid><description>&lt;p>As a student in Math 22b, taught by &lt;a href="https://www.math.harvard.edu/people/grundmeier-dusty/" id="Harvard" type="link">&lt;b>Dr. Dusty Grundmeier&lt;/b>&lt;/a>, I learned introductory proof-based vector calculus with some exposure to limits and continuity. However, I was interested in getting more exposure to real analysis, so for my final project I learned about existence and uniqueness theorems for differential equations and wrote an expository paper presenting a simple case of such a theorem.&lt;/p></description></item></channel></rss>