<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: December 8, 2023 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&family=Merriweather&family=Roboto+Mono&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&family=Merriweather&family=Roboto+Mono&display=swap" media=print onload='this.media="all"'><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.9e3515c7534a90d8339ca9703c3e3bce.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Srihari Ganesh"><meta name=description content="Lecture dates: 9/5, 9/7; Section date: 9/13"><link rel=alternate hreflang=en-us href=https://srihari-ganesh.github.io/stat110/week1/><link rel=canonical href=https://srihari-ganesh.github.io/stat110/week1/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu238e72ff877ecedb95a45ec9a2f2431b_15216_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu238e72ff877ecedb95a45ec9a2f2431b_15216_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#707070"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="twitter:image" content="https://srihari-ganesh.github.io/media/icon_hu238e72ff877ecedb95a45ec9a2f2431b_15216_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="Srihari Ganesh"><meta property="og:url" content="https://srihari-ganesh.github.io/stat110/week1/"><meta property="og:title" content="Week 1: Counting and Definitions of Probability | Srihari Ganesh"><meta property="og:description" content="Lecture dates: 9/5, 9/7; Section date: 9/13"><meta property="og:image" content="https://srihari-ganesh.github.io/media/icon_hu238e72ff877ecedb95a45ec9a2f2431b_15216_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-08-30T00:00:00+00:00"><meta property="article:modified_time" content="2023-08-30T00:00:00+00:00"><title>Week 1: Counting and Definitions of Probability | Srihari Ganesh</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=26974da8975636691009f04590ab26a6><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Srihari Ganesh</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Srihari Ganesh</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Teaching</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/#teaching><span>Experience</span></a>
<a class=dropdown-item href=/stat110><span>Stat 110 Section Notes</span></a></div></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="container-fluid docs"><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 docs-sidebar"><form class="docs-search d-flex align-items-center"><button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type=button data-toggle=collapse data-target=#docs-nav aria-controls=docs-nav aria-expanded=false aria-label="Toggle section navigation"><div class=d-flex><span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">Stat 110 Section Notes</span>
<span><i class="fas fa-chevron-down"></i></span></div></button></form><nav class="collapse docs-links" id=docs-nav><ul class="nav docs-sidenav"><li><a href=/stat110/>Stat 110 Section Notes</a></li><li><a href=/stat110/week11/>Week 11: Markov Chains</a></li><li><a href=/stat110/week10/>Week 10: Adam's & Eve's Laws, Inequalities, and Limit Theorems</a></li><li><a href=/stat110/week9/>Week 9: Transformations, Gamma/Beta, Conditional Expectation</a></li><li><a href=/stat110/week8/>Week 8: Multinomial, Multivariate Normal</a></li><li><a href=/stat110/week7/>Week 7: Poisson Processes, Joint Distributions, and Covariance</a></li><li><a href=/stat110/week6/>Week 6: Universality of the Uniform, Normal, Expo, and Moments</a></li><li><a href=/stat110/week5/>Week 5: Continuous Distributions</a></li><li><a href=/stat110/week4/>Week 4: Discrete Distributions and Expectation</a></li><li><a href=/stat110/week3/>Week 3: Conditional Probability Examples and Random Variables</a></li><li><a href=/stat110/week2/>Week 2: Conditional Probability</a></li><li class=active><a href=/stat110/week1/>Week 1: Counting and Definitions of Probability</a></li></ul></nav></div><div class="d-none d-xl-block col-xl-2 docs-toc"><ul class="nav toc-top"><li><a href=# id=back_to_top class=docs-toc-title>Contents</a></li></ul><nav id=TableOfContents><ul><li><a href=#0-info>0. Info</a></li><li><a href=#1-set-theory>1. Set Theory</a><ul><li><a href=#11-definitions>1.1 Definitions</a></li><li><a href=#12-verbal-understanding>1.2 Verbal Understanding</a></li><li><a href=#13-demorgans-laws>1.3 DeMorgan&rsquo;s Laws</a></li></ul></li><li><a href=#2-counting>2. Counting</a><ul><li><a href=#20-some-useful-problem-solving-strategies-lifted-from-95-lecture>2.0 Some useful problem-solving strategies (lifted from 9/5 lecture)</a></li><li><a href=#21-multiplication-rule>2.1 Multiplication Rule</a></li><li><a href=#22-factorial>2.2 Factorial</a></li><li><a href=#23-permutations>2.3 Permutations</a></li><li><a href=#24-binomial-coefficient>2.4 Binomial Coefficient</a></li><li><a href=#25-counting-subsets>2.5 Counting Subsets</a></li><li><a href=#26-bose-einstein>2.6 Bose-Einstein</a></li></ul></li><li><a href=#3-definitions-of-probability>3. Definitions of Probability</a><ul><li><a href=#31-naive-definition-of-probability>3.1 Naive Definition of Probability</a></li><li><a href=#32-general-definition-of-probability>3.2 General Definition of Probability</a></li></ul></li><li><a href=#4-summary>4. Summary</a><ul><li><a href=#41-set-theory>4.1 Set Theory</a></li><li><a href=#42-counting>4.2 Counting</a></li><li><a href=#43-definitions-of-probability>4.3 Definitions of Probability</a></li></ul></li><li><a href=#5-practice-problems>5. Practice Problems</a><ul><li><a href=#51-extra-practice-problems-if-you-have-time-during-section>5.1 Extra practice problems (if you have time during section)</a></li></ul></li></ul></nav></div><main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role=main><div class=docs-article-container></div><div class=docs-article-container><h1>Week 1: Counting and Definitions of Probability</h1><article class=article-style><h2 id=0-info>0. Info</h2><ul><li>Section date: 9/13</li><li>Associated lectures: 9/5, 9/7</li><li>Associated pset: Pset 1, due 9/15</li><li>Where to find me<ul><li>Section: Wednesdays 3-4:15pm, see section info on Canvas for location.<ul><li>Section will always cover content for the pset due on Friday (in two days)</li><li>Specifically, this means we&rsquo;ll focus on the lectures from the previous week (six and eight days previous), and not the lecture from the day before section</li></ul></li><li>Office Hours: Wednesdays 7-9pm, see office hours info on Canvas/Google Calendar for location. I will often stay for the office hours that come right after (Wednesday 9-11pm), and occasionally may drop by at the Thursday 7:30-9:30pm office hours in the same location as well.</li></ul></li><li>Syllabus clarifications<ul><li>Problem Sets: due Fridays at 5pm. They will cover content up to the previous week (e.g., up to the lecture 8 days before the due date).</li><li>Attendance: If your grade ends up being slightly below a grade cutoff, attendance in lecture in section may boost you over. Attendance (or lack thereof) will not be used to penalize.</li></ul></li><li>Me: Srihari Ganesh (senior)<ul><li>Concentrating in Chemical & Physical Biology and Math w/ a master&rsquo;s in Stat</li><li>Doing computational biology research in diffusion models for protein structure generation</li><li>Love teaching Stat + playing IM sports on the side</li><li>Happy to chat about everything though I&rsquo;m not an expert on anything</li></ul></li></ul><h2 id=1-set-theory>1. Set Theory</h2><div class="alert alert-note"><div><p>A <strong>set</strong> is an unordered collection of unique items. For example, $A = \{ 8, 1, 2 \}$ is a set with items (<strong>elements</strong>) $8$, $1$, and $2$.</p><ul><li>Sets are unordered, so $\{8, 1, 2 \} = \{2, 8, 1\}$.</li><li>Sets contain unique elemnts, so $\{8, 1, 2, 1\}$ is NOT a set.</li><li>Sets are a collection of any type of item, so $\{A, B, C\}$, $\{\text{car, cow, walnut}\}$, and $\{$❤️, 👨‍🏫, ⏳$\}$ are all sets.</li></ul></div></div><h3 id=11-definitions>1.1 Definitions</h3><ul><li><p>$A$ is a <strong>subset</strong> of $B$ (notated $A \subset B$ or $A \subseteq B$) if every element of $A$ is also an element of $B$.</p></li><li><p>The <strong>empty set</strong> (notated $\emptyset$) is the set with no elements, $\{\}$.</p></li><li><p>The <strong>union</strong> (notated $A \cup B$) is the set of all elements that are in $A$ or $B$ (or both).</p></li><li><p>The <strong>intersection</strong> (notated $A \cap B$) is the set of all elements that are in both $A$ and $B$.</p></li><li><p>$A$ and $B$ are <strong>disjoint</strong> if $A$ and $B$ share no elements (notated $A \cap B = \emptyset$)</p><ul><li>A collection of sets $A_1, \ldots, A_n$ are <strong>disjoint</strong> if no pair of sets shares any elements ($A_i \cap A_j = \emptyset$ for all $i, j$)</li></ul></li><li><p>A collection of sets $B_1, B_2, \ldots, B_n$ are a <strong>partition</strong> of $B$ if</p><ul><li>$B_1, B_2, \ldots, B_n$ are disjoint, and</li><li>$B_1 \cup B_2 \cup \cdots \cup B_n = B$.</li></ul><p>Intuitively, $B_1, B_2, \ldots, B_n$ are (non-overlapping) puzzle pieces that form the the puzzle, $B$, when put together.</p></li><li><p>The <strong>complement</strong> of a set $A$ (notated $A^c$) is the set of all elements not in $A$</p><ul><li>Complements have to be taken relative to some superset $S$ (notated $A \subset S$). We think of this set as the &ldquo;universe&rdquo; that $A$ lives in, and is usually implied by context.</li><li>ex. Let $S = \{1, 2, 3 \}, A = \{1, 3\}$. Then $A^c = \{2\}$.</li><li>Note that $A$ and $A^c$ partition $S$.</li></ul></li><li><p>The <strong>difference</strong> between two sets $B \setminus A$ is the set of all elements in $B$ which are not in $A$.</p><ul><li>Note that $B \cap A$, $B \setminus A$ partition $B$.</li><li>An equivalent notation is $B \setminus A = B \cap A^c$.</li></ul></li><li><p>The <strong>cardinality</strong> of a set, |A|, indicates the size of the set. For finite sets, it is the number of elements in the set.</p></li><li><p>We notate set membership in the following way: letting $A = \{8, 1, 2\}$,</p><ul><li>&ldquo;$2$ is in $A$&rdquo; is notated $2 \in A$.</li><li>&ldquo;$0$ is not in $A$&rdquo; is notated $0 \notin A$.</li></ul></li></ul><h3 id=12-verbal-understanding>1.2 Verbal Understanding</h3><p>We want to think about basic set operations in words.</p><ul><li>$x \in A$ reads as &ldquo;$x$ is in $A$&rdquo;.<ul><li>We tend to work with sets by thinking about whether some variable or number is in the (e.g., whether or not $x \in A$) instead of just looking at the set written out like $A = \{8, 1, 2\}$.</li></ul></li><li>$A \cup B$ reads as &ldquo;$A$ <em>or</em> $B$&rdquo;. So we can say $x \in A \cup B$ intuitively reads as &ldquo;$x$ is in $A$ <strong>or</strong> $x$ is in $B$&rdquo;.<ul><li>Be careful to note that we are using the inclusive or, so $A \textit{ or } B$ means $A$, $B$, or both.</li></ul></li><li>$A \cap B$ reads as &ldquo;$A$ <em>and</em> $B$&rdquo;. So $x \in A \cap B$ reads as &ldquo;$x$ is in $A$ <strong>and</strong> $x$ is in $B$&rdquo;.</li><li>$A^c$ reads as &ldquo;not $A$&rdquo;, so $x \in A^c$ reads as &ldquo;$x$ is not in $A$&rdquo;</li></ul><p>We can apply this so see that the two versions of the set difference are equivalent. $x \in B \setminus A$ reads as &ldquo;$x$ is in $B$ but not in $A$&rdquo;, while $x \in B \cap A^c$ reads as &ldquo;$x$ is in B and in $A^c$ (i.e., not in $A$).&rdquo;</p><p>What if we have multiple operations in the same expression?</p><ul><li>$x \in (A \cap B)^c$ reads as &ldquo;$x$ is not in both $A$ and $B$&rdquo;. This means that either $x$ is not in $A$ or $x$ is not in $B$, so $x \in A^c \cup B^c$.</li><li>$x \in (A \cup B)^c$ read as &ldquo;$x$ is not in $A$ or $B$&rdquo;. This means that $x$ is not in $A$ and $x$ is not in $B$, so $x \in A^c \cap B^c$.
We see in the next section that these statements are essentially DeMorgan&rsquo;s laws.</li></ul><h3 id=13-demorgans-laws>1.3 DeMorgan&rsquo;s Laws</h3><div class="alert alert-note"><div><strong>DeMorgan&rsquo;s Laws</strong>
\begin{align}
(A \cap B)^c &= A^c \cup B^c \\
(A \cup B)^c &= A^c \cap B^c
\end{align}</div></div><p>By talking through the expressions, you should eventually be able to convince yourself that the laws are true.<br>These videos also walk through the process visually:
<video controls>
<source src=/media/videos/Section1_DeMorgan1.mp4 type=video/mp4></video>
<video controls>
<source src=/media/videos/Section1_DeMorgan2.mp4 type=video/mp4></video></p><h2 id=2-counting>2. Counting</h2><h3 id=20-some-useful-problem-solving-strategies-lifted-from-95-lecture>2.0 Some useful problem-solving strategies (lifted from 9/5 lecture)</h3><ul><li>Try simple/extreme cases (i.e., set $n$ to be a small number and brute-force)<ul><li>For each tool below, we&rsquo;ll motivate it with an example. You can click the drop-down to view the example.</li></ul></li><li>Give objects of interest <em>names</em> or <em>ID numbers</em></li><li>Draw a diagram</li><li>Make a story</li></ul><h3 id=21-multiplication-rule>2.1 Multiplication Rule</h3><p><strong>How many different combinations can you make?</strong><br><details class=spoiler id=spoiler-4><summary><ins>Click for example</ins></summary><p><p>If an ice cream parlor has $4$ different flavors and $3$ different cup sizes, there are $4 \times 3 = 12$ different orders I could make.</p><p>This example exhibits all of the above problem-solving strategies. We took the general multiplication rule (see general statement below) and, made a story about an ice cream parlor, and set $a = 4$, $b=3$. We drew a diagram (the tree below), and gave the objects (flavors and cup sizes) names in that diagram.</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt="Tree diagram of the ice cream parlor example, combining four ice cream flavors and 3 cup sizes to yield 4 times 3 = 12 possible orders." srcset="/media/images/Section1_Tree_hu9544750ee73ba0725668d11c52a82e97_147874_29105694be846087f9bc432364e890bc.webp 400w,
/media/images/Section1_Tree_hu9544750ee73ba0725668d11c52a82e97_147874_9b2c3ae9f8dc6a45b203c506f9118536.webp 760w,
/media/images/Section1_Tree_hu9544750ee73ba0725668d11c52a82e97_147874_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/media/images/Section1_Tree_hu9544750ee73ba0725668d11c52a82e97_147874_29105694be846087f9bc432364e890bc.webp width=760 height=428 loading=lazy data-zoomable></div></div></figure></p></p></details></p><p><ins>General statement</ins>: Say the outcome of a full experiment is given by the outcomes of two-subexperiments, $A$ and $B$. If sub-experiment $A$ has $a$ possible outcomes and sub-experiment $B$ has $b$ possible outcomes, then the full experiment has $a \times b$ possible outcomes.</p><ul><li>Note here that this will work as long as the outcome of $A$ doesn&rsquo;t change the <em>number</em> of possible outcomes of $B$, even if $A$ changes <em>which</em> outcomes are possible for $B$.</li></ul><h3 id=22-factorial>2.2 Factorial</h3><p><strong>How many ways can you order $n$ distinct items?</strong><br><details class=spoiler id=spoiler-5><summary><ins>Click for example</ins></summary><p>How many ways can $n=52$ card deck of cards be shuffled? I have $52$ options for the first card, then $52-1 = 51$ options for the second card, $52-2 = 50$ options for the third card, and so on. The total number of ways is thus $$52 \times 51 \times 50 \times \cdots \times 2 \times 1.$$</p></details></p><p><ins>General statement</ins>: We use the factorial, $n!$, as a shorthand for this specific application of the multiplication rule. We have $n$ choices for the first item; we can then pick $(n-1)$ choices for the second item, and so on, giving
$$
n! = n \times (n-1) \times (n-2) \cdots \times 2 \times 1.
$$</p><h3 id=23-permutations>2.3 Permutations</h3><p><strong>How many ways can you choose an ordered collection of $k$ distinct items from a set of $n$ distinct items?</strong><br><details class=spoiler id=spoiler-6><summary><ins>Click for example</ins></summary><p>I want to take a $k=3$ week trip in New England, spending each week in a different state. New England has $n=6$ states, so using the multiplication rule, I have $6 \times 5 \times 4 = 120$ possible trips I can go on.</p></details><ins>General statement</ins>: Using the multiplication rule, the solution is
$$
n \times (n-1) \times \cdots \times (n-k+1) = \frac{n!}{(n-k)!}.
$$</p><div class="alert alert-warning"><div><p>Be careful with off-by-one errors when you&rsquo;re listing consecutive integers.</p><p>For a list of $k$ consecutive integers, the first and last numbers should have a difference of $k-1$.</p><p>For example, the list &ldquo;$3, 4, 5, 6$&rdquo; has $4$ items, so the difference between the first and last numbers if $6-3 = 3 = 4-1$.</p></div></div><p><strong>How many ways can you order a set of $n$ items, where some items are repeated?</strong><br><details class=spoiler id=spoiler-8><summary><ins>Click for example</ins></summary><p><p>How many anagrams (orderings/permutations) are there of the word &ldquo;BANANA&rdquo;? In other words, how many $n=6$ letter words have 3 A&rsquo;s, 1 B, and 2 N&rsquo;s?</p><p>If we treated the letters as distinct, there would be $6!$ ways to order them. However, the 3 A&rsquo;s are identical, so we are overcounting. For example, if we artificially distinguish the A&rsquo;s, we see that<br>&ldquo;B<em>A</em>N<strong>A</strong>N<ins>A</ins>&rdquo;, &ldquo;B<strong>A</strong>N<em>A</em>N<ins>A</ins>&rdquo;, &ldquo;B<ins>A</ins>N<strong>A</strong>N<em>A</em>&rdquo;, &ldquo;B<ins>A</ins>N<em>A</em>N<strong>A</strong>&rdquo;, &ldquo;B<strong>A</strong>N<ins>A</ins>N<em>A</em>&rdquo;, and &ldquo;B<em>A</em>N<ins>A</ins>N<strong>A</strong>&rdquo;<br>are all counted as different words. This means there we are overcounting the orderings of the 3 A&rsquo;s by $3!$, so we can divide to get $6!/3!$.<br>Similarly, we are overcounting the orderings of the 2 N&rsquo;s by $2!$. There is only one B, so we are not overcounting that. This gives a final answer of $\frac{6!}{3!2!} = 120$ orderings.</p></p></details></p><p><ins>General statement</ins>: say we have $n$ items total with $m$ types, made up of $n_1$ items of type 1, $n_2$ items of type 2, and so forth, with $n = \sum_{i=1}^m n_i$. Then the number of permutations is
\begin{equation}
\frac{n!}{n_1! n_2! \cdots n_m!}.
\end{equation}</p><h3 id=24-binomial-coefficient>2.4 Binomial Coefficient</h3><p><strong>How many ways can you choose an unordered group of $k$ items, without replacement, from a set of $n$ distinct items?</strong><br>In order words, if a set has $n$ elements, how many subsets with exactly $k$ elements does it have?</p><details class=spoiler id=spoiler-9><summary><ins>Click for example</ins></summary><p><p>From my $n=4$ nuclear family members, how many ways can I choose $k=2$ of them to go on an all-expenses paid trip to Cambridge, Massachusetts with me?</p><p>I can use the multiplication rule, so I have $4$ options for the first family member and $3$ options for the second. However, I don&rsquo;t care about the order, so I can divide by $2!$ to get $\frac{4 \times 3}{2!} = 6$ unordered groups of $2$ family members.</p></p></details><p><ins>General statement</ins>: <a href=#23-permutations>Using our previous permutation result</a>, we can first pick $k$ items in order: $n \times (n-1) \times \cdots \times (n-k+1) = \frac{n!}{(n-k)!}$.</p><p>Since we don&rsquo;t care about the order, we can then correct our overcounting by dividing by $k!$ to get the answer, which is called the <strong>binomial coefficient</strong>:
\begin{equation}
\binom{n}{k} = \frac{n!}{k!(n-k)!}.
\end{equation}</p><h3 id=25-counting-subsets>2.5 Counting Subsets</h3><p><strong>How many ways can you select an unordered group of items (of any size, including $0$), without replacement, from a set of $n$ distinct items?</strong><br>Alternatively worded, given a set of size $n$, how many different subsets can you come up with (including the empty set)?</p><p>The first item of the set is either in the the group or not, so there are 2 possibilities. This applies for each item in the set &mdash; it is either in the group or not. We can apply the multiplication rule to get the that the number of possible groups is
\begin{equation}
2 \times 2 \times \cdots \times 2 = 2^n.
\end{equation}</p><h3 id=26-bose-einstein>2.6 Bose-Einstein</h3><p><strong>How many ways can you choose an unordered group of $k$ items, with replacement, from a set of $n$ items?</strong></p><details class=spoiler id=spoiler-10><summary><ins>Click for example</ins></summary><p><p>At a donut shop with $n=3$ different flavors, how many ways distinct orders of $k=5$ donuts can I make?</p><p>Let&rsquo;s start with smaller values of $n$ and up the complexity. With only $n=1$ flavor, there&rsquo;s only one possible order (all donuts of one flavor). With $n=2$ flavors (e.g., frosted and glazed), the order is uniquely determined by how many frosted donuts there are; for example, if we have $3$ frosted donuts, we know there must be $5-3$ glazed donuts. In the example below, we say that the donuts to the left of the divider are frosted, and those to the right are glazed.</p><video controls>
<source src=/media/videos/Section1_BE1.mp4 type=video/mp4></video><p>For larger $n$, we follow a similar idea and count in a clever way. Your order can be uniquely represented by how many donuts of each flavor you buy, so we can think of placing dividers between donuts to uniquely represent our order. Each &ldquo;box&rdquo; created by the dividers represents a flavor: those to the left of the first divider are frosted, between the first and second divider are glazed, between the second and third divider are jam, etc.</p><video controls>
<source src=/media/videos/Section1_BE2.mp4 type=video/mp4></video><p>Note that we need $4-1 = 3$ dividers to create $4$ categories. So how do we count ways to put $2$ dividers among $5$ donuts? We&rsquo;ll count by treating dividers as distinguishable, then correct for the overcounting later. We have $5+1=6$ options for where to put the first divider (to the left of the first donut, between the first and second donut, etc.). The second divider has $5+1+1=7$ optinos, since there are now $6$ items ($5$ donuts, $1$ divider) that we can go between or to the left/right of. The third divider has $5+2+1=8$ options. By this pattern, we have $6 \times 7 \times 8$ ways to place dividers. However, the dividers themselves don&rsquo;t tell us anything about how the donuts are divied up - only their locations - so we don&rsquo;t care about the order they were placed. Thus, we divide by $3!$ ways to order the dividers to get $\frac{6 \times 7 \times 8}{3!} = \binom{8}{3}$.</p><p>Another way to think about this is that we have $5 + (4-1) = 8$ &ldquo;slots&rdquo; (donuts and dividers) in a row, and we need to pick out the locations of the $3$ dividers. We can use the binomial coefficient to do this in $\binom{8}{3}$ ways.</p></p></details><p>I encourage you to check out the example above for much of the derivation of the Bose-Einstein counting method.</p><p><ins>General statement</ins>: We are trying to split the $k$ items into $n$ categories, which we can do by placing $n-1$ dividers between the $k$ items. We can re-frame this problem as selecting the locations of $n-1$ dividers from $(n-1)+k$ slots (items + dividers), which means our solution is $$\binom{n-1+k}{n-1} = \binom{n-1+k}{k}.$$</p><p>Note: Bose-Einstein is a bit of a &ldquo;big hammer&rdquo; &mdash; it can solve some pretty complicated problems, but also some simpler ones. You should make sure you have exhausted your other tools, and that your problem matches the &ldquo;unordered, with replacement&rdquo; requirement before trying this out.</p><h2 id=3-definitions-of-probability>3. Definitions of Probability</h2><ul><li>The <strong>sample space</strong> $S$ is the set of all possible <strong>outcomes</strong> of an experiment (i.e., each element of $S$ is a unique outcome).<ul><li>After an experiment is completed, exactly one of the outcomes will have occurred.</li></ul></li><li>An <strong>event</strong> $A$ is any subset of $S$ ($A \subset S$) - anything that we could say either &ldquo;happened&rdquo; or &ldquo;didn&rsquo;t happen&rdquo; once the experiment takes place. We calculate the probabilities of events (e.g., the probability that an event $A$ happens).<ul><li>After an experiment is completed, every event will have<ul><li>&ldquo;Happened&rdquo; or &ldquo;happened&rdquo; if it contains the outcome which actually occurred.</li><li>&ldquo;Not happened&rdquo; or &ldquo;not occurred&rdquo; if it does not contain the outcome which actually occured.</li></ul></li></ul></li></ul><h3 id=31-naive-definition-of-probability>3.1 Naive Definition of Probability</h3><details class=spoiler id=spoiler-11><summary><ins>Click for example</ins></summary><p><p>When rolling a standard die, the sample space is typically denoted by $S = \{1, 2, 3, 4, 5, 6\}$, where each element of $S$ is a possible outcome.</p><p>Possible events could be rolling a $1$ (the event being $A = \{1\}$), rolling an odd number, $B = \{1, 3, 5\}$, or rolling a small number $C = \{1, 2, 3\}$.</p><p>For a fair die, you might intuitively know that the probability of $A$ is $1/6$, the probability of $B$ is $3/6=1/2$, and the probability of $C$ is $3/6=1/2$. Also see that it&rsquo;s possible that the events $A, B, C$ all occur, even though only one outcome actually occur.</p><video controls>
<source src=/media/videos/Section1_Events.mp4 type=video/mp4></video></p></details><div class="alert alert-note"><div><strong>Naive definition of probability</strong>:<br>We assume that there are a finite number of outcomes (the sample space, $S$, is finite), and that each individual outcome has an equal probability of occuring. Then the probability of an event $A$ is.
$$
P_{\text{naive}}(A) = \frac{\text{# of outcomes in $A$}}{\text{# of outcomes in $S$}} = \frac{|A|}{|S|}.
$$</div></div><p>Limitations:</p><ul><li>Assumes that all outcomes are equally likely<ul><li>Shaky definition of what &ldquo;equally likely&rdquo; means because we can arbitrarily construct the outcomes.</li><li><em>ex.</em> Say the weather tomorrow has two possible outcomes: $\{\text{precipitation}, \text{no precipitation}\}$. By the naive definition, there&rsquo;s a $50%$ chance of no precipitation.<br>Alternatively, I could have said the possible outcomes are $\{\text{rain}, \text{sleet}, \text{hail}, \text{snow}, \text{no precipitation}\}$. Then there&rsquo;s only a $20%$ chance of no precipitation&mldr; so which is it?</li></ul></li><li>Assumes the sample space is finite<ul><li>What if the sample space is of possible temperatures? There are infinitely many possible temperatures, they can&rsquo;t each have a $1/\infty$ probability.</li></ul></li></ul><h3 id=32-general-definition-of-probability>3.2 General Definition of Probability</h3><div class="alert alert-note"><div><p><strong>Definition of probability</strong>:<br>There are just two axioms (rules that probabilities have to follow):</p><ol><li>$P(S) = 1, P(\emptyset) = 0.$</li><li>If events $A_1, A_2, \ldots$ are disjoint, then $$
P\left( \bigcup_{j=1}^\infty A_j\right) = \sum_{j=1}^\infty P(A_j).
$$</li></ol><p>In other words, if $A_1, A_2, \ldots$ partition some event $B$, then $P(B) = \sum_{j=1}^\infty P(A_j)$.</p></div></div><h4 id=321-probability-of-complements>3.2.1 Probability of Complements</h4><p>Let&rsquo;s say we know the probability of some event $A$. Then $$P(A^c) = 1 - P(A).$$ This follows directly from the axioms of probability: since $A^c, A$ partition the sample space $S$, we know $P(A) + P(A^c) = P(S) = 1$. When you&rsquo;re asked to calculate the probability of events in the form of &ldquo;at least&rdquo; or &ldquo;at most&rdquo;, the probability of the complement may sometimes be simpler to calculate.</p><h4 id=322-principle-of-inclusion-exclusion-pieprobability-of-unions>3.2.2 Principle of Inclusion-Exclusion (PIE)/Probability of unions</h4><p>Say we have two events (not necessarily disjoint) $A$ and $B$. We can partition $A \cup B$ into $A \setminus B, A \cap B, B \setminus A$.
\begin{align*}
P(A \cup B) &= P(A \setminus B) + P(A \cap B) + P(B \setminus A)\\
P(A \cup B) &= P(A \setminus B) + P(A \cap B) + P(B \setminus A) + P (A \cap B) - P(A \cap B)\\
P(A \cup B) &= P(A) + P(B) - P(A \cap B),
\end{align*}
where we apply the second axiom of probability using the fact that $A \setminus B, A \cap B$ partition $A$ and the fact that $B \setminus A, A \cap B$ partition $B$.</p><p>This extends to finding the probability of the union of any $n$ events, which is called the <strong>Principle of Inclusion-Exclusion (PIE)</strong>
\begin{align*}
P(A_1 \cup A_2 \cup \cdots \cup A_n) &= \sum_{i=1}^n P(A_i) - \sum_{i&lt;j} P(A_i \cap A_j) + \sum_{i &lt; j &lt; k} P(A_i \cap A_j \cap A_k) \\
&- \cdots + (-1)^{n-1} P(A_1 \cap A_2 \cap \cdots \cap A_n).
\end{align*}</p><p>We are a bit careless with notation in the sums: $\sum_{i&lt;j}$ means that we sum over every (unordered) pair of events. This formula is better remembered in words: add up the probabilities of all individual events, subtract the probabilities of every pair, add back the probabilities of every triple, etc.; remember that you start positive, then alternate signs.</p><p>PIE is another tool that is a big hammer: it will always work if you&rsquo;re finding the probability of a union (the probability that at least one event occurs), but it is unwieldy for most problems and should be one of your last resorts.</p><h2 id=4-summary>4. Summary</h2><h3 id=41-set-theory>4.1 Set Theory</h3><ul><li><strong>Sets</strong>: unordered collections of items</li><li>Important set operations: intersection, union, complement, difference, cardinality</li><li>Important properties: set membership, subsets, disjoint sets, partitions</li><li>Theorems: DeMorgan&rsquo;s laws</li></ul><h3 id=42-counting>4.2 Counting</h3><p>All of our counting is driven by the multiplication rule. Here&rsquo;s what we&rsquo;ve built from that, working from a set of $n$ distinct items:</p><table><thead><tr><th>select how many items?</th><th>ordered or unordered?</th><th>with or without replacement?</th><th>solution</th></tr></thead><tbody><tr><td>take all $n$ items,</td><td>order the items,</td><td>without replacement</td><td>n!</td></tr><tr><td>select $k$ items,</td><td>ordered,</td><td>without replacement</td><td>$\frac{n!}{(n-k)!}$</td></tr><tr><td>select $k$ items,</td><td>unordered,</td><td>without replacment</td><td>$\binom{n}{k}$</td></tr><tr><td>select any number of items,</td><td>unordered,</td><td>without replacement</td><td>$2^n$</td></tr><tr><td>select $k$ items,</td><td>unordered,</td><td>with replacement</td><td>$\binom{n+k-1}{k}$</td></tr><tr><td>select $k$ items,</td><td>ordered,</td><td>with replacement</td><td>$n^k$</td></tr></tbody></table><p>You may also have seen this sampling table (below) in lecture (for counting the numbers of ways to draw a sample of $k$ items from $n$ distinct items). I suggest breaking down every counting problem into whether order matters and whether you are sampling with replacement, and trying out the corresponding approach in the table.</p><table><thead><tr><th></th><th>Order matters</th><th>Order doesn&rsquo;t matter</th></tr></thead><tbody><tr><td>With replacement</td><td>$n^k$</td><td>$\binom{n+k-1}{k}$</td></tr><tr><td>Without replacement</td><td>$\frac{n!}{(n-k)!}$</td><td>$\binom{n}{k}$</td></tr></tbody></table><p>We also talked about the permutation problem with $n$ items that aren&rsquo;t necessarily distinct (order all $n$ items without replacement), where we compensate for overcounting after the fact: $$\frac{n!}{n_1! n_2! \cdots n_m!}.$$</p><h3 id=43-definitions-of-probability>4.3 Definitions of Probability</h3><p><strong>Naive probability</strong>: probably the most intuitive (and yet very flawed) way to define probability: the probability is proportional to the number of outcomes. For example, there are 3 ways to roll an even number on a die, so by this definition, there is a $3/6 = 1/2$ probability of rolling an even number.</p><p><strong>(Non-naive) probability</strong>: given by two axioms:</p><ol><li>$P(S) = 1$</li><li>$P\left(\bigcup_{j=1}^\infty A_j \right) = \sum_{j=1}^\infty P(A_j)$ for $A_1, A_2, \ldots$ disjoint.</li></ol><p>The principle of inclusion-exclusion and the probability of complements follow from the axioms.</p><h2 id=5-practice-problems>5. Practice Problems</h2><p><a href=/uploads/stat110/Section%201%20Practice%20Problems.pdf target=_blank>Practice Problem PDF</a></p><p><a href=/uploads/stat110/Section%201%20Solutions.pdf target=_blank>Practice Problem Solutions PDF</a></p><ol><li><p>I am interested in five subjects (statistics, math, computer science, chemistry, and biology) and am deciding between 100, 102, 110, and 111 in each department (e.g., my options are Stat 100, Stat 102, Stat 110, Stat 111, Math 100, Math 102, etc.). Assume unless stated otherwise that each class (or set of classes) is equally likely to be chosen if possible.</p><ol><li>How many different schedules of four courses can I take?</li><li>I want to send my friend a text of my 4-class schedule. My text will look be a list like &ldquo;Chemistry 101, Stat 110, Biology 111, Math 101&rdquo;, which is considered a different text from &ldquo;Stat 110, Chemistry 101, Biology 111, Math 101&rdquo;. How many different such texts could I send?</li><li>If I take 5 courses, what is the probability that I take exactly 1 course from each department?</li><li>My advisor wants to know that I have backup plans, so they ask me to send 2 schedules with 4 courses each, where the schedules can have no overlap. How many such sets of two schedules can I send my advisor?</li><li>After I finalize my schedule, my advisor now wants to know how many classes I&rsquo;m taking in each subject, so I send them a list that follows the following format of the following example (with the subjects always in this order):<br><br>[Statistics: 2, Math: 0, Computer Science: 1, Chemistry: 1, Biology: 1]<br><br>How many such lists can I send for a 4-class schedule?</li><li>If I take 6 courses, what is the probability that there&rsquo;s at least 1 subject in which I am not taking any courses? Solve this problem in two ways.</li></ol></li><li><p><em>(Problem statement taken from Rachel Li and Ginnie Ma&rsquo;s notes)</em> Hockey Stick Identity: show using a story proof that
$$
\sum_{j=k}^n \binom{j}{k} = \binom{n+1}{k+1}.
$$
Hint: Imagine arranging a group of people by age, and then think about the oldest person in a chosen subgroup.</p></li><li><p>Use problem 1.4 to construct a story proof for the following identity (assuming $n \ge 2k$). Recall that in problem 1.4, my advisor asked me to make 2 (non-overlapping) schedules with 4 courses each.
$$
\binom{n}{2k} \binom{2k}{k} = \binom{n}{k}\binom{n-k}{k}
$$</p></li></ol><h3 id=51-extra-practice-problems-if-you-have-time-during-section>5.1 Extra practice problems (if you have time during section)</h3><p><em>Taken from the section materials of Rachel Li and Ginnie Ma (&lsquo;23)</em></p><ol start=4><li><p>(<strong>Lattice Walks</strong>) You start at the origin of a grid. Assuming you can only move up or to the right one unit at a time, how many different paths exist between you and position $(10, 10)$? Next, assume you are in a 3D-space. How many different paths exist between you and position $(10, 10, 10)$? Last, say your motions are defined by a 2-dimensional random walk: where you either walk right or up one unit with equal probability. After 20 steps, what is the probability that you are at position $(10, 10)$?</p></li><li><p>(<strong>Coin Toss Gambling</strong>, <em>Question Credit: Zhou, 2008</em>) Two gamblers are playing a coin toss game. Gambler A has $(n + 1)$ fair coins. Gambler B has $n$ fair coins. What is the probability that A will have more heads than B if they all flip their coins?<br><em>Hint: What are the possible results (events) if we compare the number of heads in A’s first $n$ coins with B’s $n$ coins? By making the number of coins equal, we can take advantage of symmetry. For each event, what will happen if A’s last coin is a head? Or Tails?</em></p></li><li><p>(<strong>Teenager Steps</strong>) A teenage boy recently went through his first growth spurt, and can now walk up stairs one or two stairs at a time. How many different ways are there for him to ascend to the top of a staircase with $n$ stairs?<br><em>Hint: start with small $n$. The solution should look familiar!</em></p></li></ol></article><div class=article-tags><a class="badge badge-light" href=/tag/expository/>expository</a>
<a class="badge badge-light" href=/tag/teaching/>teaching</a></div><div class=article-widget><div class=post-nav><div class=post-nav-item><div class=meta-nav>Previous</div><a href=/stat110/week2/ rel=next>Week 2: Conditional Probability</a></div></div></div></div><div class=body-footer><p>Last updated on Aug 30, 2023</p></div><footer class=site-footer><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></main></div></div></div><div class=page-footer></div><script src=/js/vendor-bundle.min.f64289d8217e08e3afcd597d60836062.js></script>
<script src=https://cdn.jsdelivr.net/npm/anchor-js@5.0.0/anchor.min.js integrity="sha256-aQmOEF2ZD4NM/xt4hthzREIo/2PFkOX/g01WjxEV7Ys=" crossorigin=anonymous></script>
<script>anchors.add()</script><script id=page-data type=application/json>{"use_headroom":false}</script><script src=/en/js/wowchemy.min.387a7b38a3dfead6f96c96742d20f5af.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>